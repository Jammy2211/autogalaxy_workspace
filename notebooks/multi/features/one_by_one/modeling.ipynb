{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: One By One\n",
        "=============================\n",
        "\n",
        "Multi-wavelength analysis does not necessarily require us to fit all datasets simultaneously. Instead, we can fit one\n",
        "dataset first in order to infer a robust galaxy model, and then fit the next dataset, using the inferred\n",
        "model as the starting point.\n",
        "\n",
        "There are many occasions where this approach is beneficial, for example:\n",
        "\n",
        "- When certain datasets are worse quality (e.g. lower resolution) than others. Fitting them simultaneously may mean this\n",
        "  dataset's lower quality makes the model fit less robust. By fitting them one by one, using the inferred model of the\n",
        "  best dataset first, we can ensure the model-fit is as robust as possible and interpret the results of the lower\n",
        "  quality datasets more clearly.\n",
        "\n",
        "- It can often produce faster run times, as although more non-linear searches are performed, each search is faster\n",
        "  than a search which fits all datasets simultaneously.\n",
        "\n",
        "- To investigate whether modeling results inferred when we model all datasets simultanoeusly are robust. If the\n",
        "  result disappears for fits to individual datasets, this may suggest the result is not robust.\n",
        "\n",
        "To perform modeling one-by-one, we have to make decision about how simple or complex we make the model after\n",
        "fitting the highest quality dataset. For example, we may:\n",
        "\n",
        "- Fix the majority of galaxy structural parameters, allowing only the `intensity` values to vary.\n",
        "\n",
        "- Allow all parameters to vary, but use the highest quality dataset's inferred model as the starting point.\n",
        "\n",
        "- Whether to account for offsets between the datasets, or to assume the datasets are aligned.\n",
        "\n",
        "We illustrate different examples in this script, with the appropriate choice depending on your specific science case.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits multiple multi-wavelength `Imaging` datasets of a galaxy with a model where:\n",
        "\n",
        " - The galaxy's light is a linear parametric `Sersic` bulge and `Exponential` disk.\n",
        "\n",
        "Two images are fitted, corresponding to a greener ('g' band) and redder image (`r` band).\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Colors__\n",
        "\n",
        "The colors of the multi-wavelength image, which in this case are green (g-band) and red (r-band).\n",
        "\n",
        "The strings are used for load each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "color_list = [\"g\", \"r\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Scales__\n",
        "\n",
        "Every multi-wavelength dataset can have its own unique pixel-scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales_list = [0.08, 0.12]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot each multi-wavelength dataset, using a list of their waveband colors.\n",
        "\n",
        "The plotted images show that the datasets have a small offset between them, half a pixel based on the resolution of\n",
        "the second image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"multi\"\n",
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"simple\"\n",
        "\n",
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_label / dataset_name\n",
        "\n",
        "dataset_list = [\n",
        "    ag.Imaging.from_fits(\n",
        "        data_path=Path(dataset_path) / f\"{color}_data.fits\",\n",
        "        psf_path=Path(dataset_path) / f\"{color}_psf.fits\",\n",
        "        noise_map_path=Path(dataset_path) / f\"{color}_noise_map.fits\",\n",
        "        pixel_scales=pixel_scales,\n",
        "    )\n",
        "    for color, pixel_scales in zip(color_list, pixel_scales_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the galaxy.\n",
        "\n",
        "For multi-wavelength modeling, we use the same mask for every dataset whenever possible. This is not\n",
        "absolutely necessary, but provides a more reliable analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_list = [\n",
        "    ag.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "    for dataset in dataset_list\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    dataset.apply_mask(mask=mask) for imaging, mask in zip(dataset_list, mask_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We create an `Analysis` object for every dataset.\n",
        "\n",
        "We do not combine the analyses using a factor graph, like we do in most other example scripts, as we are going to fit \n",
        "each dataset one-by-one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    ag.AnalysisImaging(dataset=dataset, use_jax=True) for dataset in dataset_list\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our galaxy model using `Model` objects, which represent the galaxies we fit to our data. In this \n",
        "example we fit a galaxy model where:\n",
        "\n",
        " - The galaxy's bulge is a linear parametric `Sersic` bulge [6 parameters]. \n",
        " \n",
        " - The galaxy's disk is a linear parametric `Exponential` disk [6 parameters].\n",
        " \n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(ag.lp_linear.Sersic)\n",
        "disk = af.Model(ag.lp_linear.Exponential)\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"multi\") / \"modeling\",\n",
        "    name=\"one_by_one__main_dataset\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by this model-fit is a `Result` object. It is not a list like other examples, because we \n",
        "did not use a combined analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the result's galaxy shows it at this wavelength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies_plotter = aplt.GalaxiesPlotter(\n",
        "    galaxies=result.max_log_likelihood_galaxies, grid=result.grids.lp\n",
        ")\n",
        "galaxies_plotter.subplot_galaxies()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Second Dataset Bulge Model Fixed__\n",
        "\n",
        "We now fit the second dataset using the inferred model of the first dataset as the starting point.\n",
        "\n",
        "We compose a simple model where the bulge is fixed to the result of the first dataset fit, and galaxy's disk parameters\n",
        "are varied. \n",
        "\n",
        "This is a bit of a strange model to fit, and is done for illustrative purposes. \n",
        "\n",
        "The code below uses the search chaining API to link the priors between model parameters, if you are not\n",
        "familiar with this feature, checkout the `imaging/advanced/chaining` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        galaxy=af.Model(\n",
        "            ag.Galaxy,\n",
        "            redshift=result.instance.galaxies.galaxy.redshift,\n",
        "            bulge=result.instance.galaxies.galaxy.bulge,\n",
        "            disk=result.model.galaxies.galaxy.disk,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(model.info)\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"multi\") / \"modeling\",\n",
        "    name=\"one_by_one__second_bulge_fixed\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")\n",
        "\n",
        "result_bulge_fixed = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Second Dataset Offset__\n",
        "\n",
        "Multi-wavelength datasets often have offsets between their images, which are due to the different telescope pointings\n",
        "during the observations.\n",
        "\n",
        "These offsets are often accounted for during the data reduction process, but may not be perfectly corrected and\n",
        "have uncertainties associated with them.\n",
        "\n",
        "Fitting datasets one-by-one offers a straightforward method to account for these offsets, by allowing the offset\n",
        "between the datasets to vary during the model-fit as two free parameters (y and x).\n",
        "\n",
        "We now fit for the offset between datasets, keeping all model parameters fixed to the result of the first dataset\n",
        "fit. \n",
        "\n",
        "In this example, the two datasets are not offset, so the model-fit will infer an offset consistent with (0.0\", 0.0\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_model = af.Model(ag.DatasetModel)\n",
        "\n",
        "dataset_model.grid_offset.grid_offset_0 = af.UniformPrior(\n",
        "    lower_limit=-0.1, upper_limit=0.1\n",
        ")\n",
        "dataset_model.grid_offset.grid_offset_1 = af.UniformPrior(\n",
        "    lower_limit=-0.1, upper_limit=0.1\n",
        ")\n",
        "\n",
        "model = af.Collection(\n",
        "    dataset_model=dataset_model,\n",
        "    galaxies=result.instance.galaxies,\n",
        ")\n",
        "\n",
        "print(model.info)\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"multi\") / \"modeling\",\n",
        "    name=\"one_by_one__dataset_offset\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autogalaxy_workspace/*/results` for a full description of analysing results in **Pyautogalaxy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}