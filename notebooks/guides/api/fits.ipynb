{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fits\n",
        "====\n",
        "\n",
        "This guide shows how to fit data using the `FitImaging` object, including visualizing and interpreting its results.\n",
        "\n",
        "This tutorial shows how to use galaxies, including visualizing and interpreting their properties.\n",
        "\n",
        "The first half of this tutorial repeats the over example `overview/overview_2_fit.py` and contains the\n",
        "following:\n",
        "\n",
        "The guide then extends the overview with more advanced uses of galaxies, including:\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autogalaxy_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoGalaxy**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The guide `guides/units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses.\n",
        "\n",
        "__Data Structures__\n",
        "\n",
        "Quantities inspected in this example script use **PyAutoGalaxy** bespoke data structures for storing arrays, grids,\n",
        "vectors and other 1D and 2D quantities. These use the `slim` and `native` API to toggle between representing the\n",
        "data in 1D numpy arrays or high dimension numpy arrays.\n",
        "\n",
        "This tutorial will only use the `slim` properties which show results in 1D numpy arrays of\n",
        "shape [total_unmasked_pixels]. This is a slimmed-down representation of the data in 1D that contains only the\n",
        "unmasked data points\n",
        "\n",
        "These are documented fully in the `autogalaxy_workspace/*/guides/data_structures.ipynb` guide.\n",
        "\n",
        "__Other Models__\n",
        "\n",
        "This tutorial does not use a pixelized source reconstruction or linear light profiles, which have their own dediciated\n",
        "functionality that interfacts with the `FitImaging` object.\n",
        "\n",
        "This is described in the dedicated example scripts `modeling/features/linear_light_profiles.py`\n",
        "and `modeling/features/pixelizaiton.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data__\n",
        "\n",
        "We we begin by loading the galaxy dataset `simple__sersic` from .fits files, which is the dataset we will use to \n",
        "demonstrate fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"sersic_x2\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the `ImagingPlotter` to plot the image, noise-map and psf of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.figures_2d(data=True, noise_map=True, psf=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ImagingPlotter` also contains a subplot which plots all these properties simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grid__\n",
        "\n",
        "When calculating the amount of emission in each image pixel from galaxies, a two dimensional line integral of all of \n",
        "the emission within the area of that pixel should be performed. However, for complex models this can be difficult \n",
        "to analytically compute and can lead to slow run times.\n",
        "\n",
        "Instead, an iterative algorithm is used to approximate the line integral. Grids of increasing resolution are used to \n",
        "evaluate the flux in each pixel from the lens and source galaxies. Grids of higher resolution are used until the \n",
        "fractional accuracy of the flux in each pixel meets a certain threshold, which we set below to 99.99%\n",
        "\n",
        "This uses the `OverSamplingIterate` object, which is input into to the `Grid2D` object you may have seen in other \n",
        "example scripts, however it make sit perform the iterative ray-tracing described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_over_sampling(\n",
        "    over_sampling=ag.OverSamplingDataset(\n",
        "        uniform=ag.OverSamplingIterate(\n",
        "            fractional_accuracy=0.9999,\n",
        "            sub_steps=[2, 4, 8, 16],\n",
        "        )\n",
        "    )\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We next mask the data, so that regions where there is no signal (e.g. the edges) are omitted from the fit.\n",
        "\n",
        "To do this we can use a ``Mask2D`` object, which for this example we'll create as a 3.0\" circle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now combine the imaging dataset with the mask.\n",
        "\n",
        "Here, the mask is also used to compute the `Grid2D` we used in the previous overview to compute the light profile \n",
        "emission, where this grid has the mask applied to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=dataset.grid)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is what our image looks like with the mask applied, where PyAutoGalaxy has automatically zoomed around the mask\n",
        "to make the galaxyed source appear bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fitting__\n",
        "\n",
        "Following the previous overview, we can make a collection of galaxies from light profiles and individual galaxy objects..\n",
        "\n",
        "The combination of light profiles below is the same as those used to generate the simulated dataset we loaded above.\n",
        "\n",
        "It therefore produces galaxies whose image looks exactly like the dataset. As discussed in the previous overview, \n",
        "galaxies can be extended to include additional light profiles and galaxy objects, for example if you wanted to fit data\n",
        "with multiple galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_0 = ag.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=ag.lp.Sersic(\n",
        "        centre=(0.0, -1.0),\n",
        "        ell_comps=(0.25, 0.1),\n",
        "        intensity=0.1,\n",
        "        effective_radius=0.8,\n",
        "        sersic_index=2.5,\n",
        "    ),\n",
        ")\n",
        "\n",
        "galaxy_1 = ag.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=ag.lp.Sersic(\n",
        "        centre=(0.0, 1.0),\n",
        "        ell_comps=(0.0, 0.1),\n",
        "        intensity=0.1,\n",
        "        effective_radius=0.6,\n",
        "        sersic_index=3.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "galaxies = ag.Galaxies(galaxies=[galaxy_0, galaxy_1])\n",
        "\n",
        "galaxies_plotter = aplt.GalaxiesPlotter(galaxies=galaxies, grid=dataset.grid)\n",
        "galaxies_plotter.figures_2d(image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the `FitImaging` object to fit the galaxies to the dataset. \n",
        "\n",
        "The fit performs the necessary tasks to create the `model_image` we fit the data with, such as blurring the\n",
        "image of the galaxies with the imaging data's Point Spread Function (PSF). We can see this by comparing the galaxies \n",
        "image (which isn't PSF convolved) and the fit`s model image (which is).\n",
        "\n",
        "[For those not familiar with Astronomy data, the PSF describes how the observed emission of the galaxy is blurred by\n",
        "the telescope optics when it is observed. It mimicks this blurring effect via a 2D convolution operation]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = ag.FitImaging(dataset=dataset, galaxies=galaxies)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.figures_2d(model_image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit creates the following:\n",
        "\n",
        " - The `residual_map`: The `model_image` subtracted from the observed dataset`s `image`.\n",
        " - The `normalized_residual_map`: The `residual_map `divided by the observed dataset's `noise_map`.\n",
        " - The `chi_squared_map`: The `normalized_residual_map` squared.\n",
        "\n",
        "we'll plot all 3 of these, alongside a subplot containing them all, which also shows the data,\n",
        "model image and individual galaxies in the fit.\n",
        "\n",
        "For a good model where the model image and galaxies are representative of the galaxy system the\n",
        "residuals, normalized residuals and chi-squared are minimized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter.figures_2d(\n",
        "    residual_map=True, normalized_residual_map=True, chi_squared_map=True\n",
        ")\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall quality of the fit is quantified with the `log_likelihood` (the **HowToGalaxy** tutorials explains how\n",
        "this is computed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bad Fit__\n",
        "\n",
        "In contrast, a bad model will show features in the residual-map and chi-squared map.\n",
        "\n",
        "We can produce such an image by using different galaxies. In the example below, we \n",
        "change the centre of the galaxies from (0.0, -1.0) to (0.0, -1.05), and from (0.0, 1.0) to (0.0, 1.05) which leads to \n",
        "residuals appearing in the centre of the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_0 = ag.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=ag.lp.Sersic(\n",
        "        centre=(0.0, -1.05),\n",
        "        ell_comps=(0.25, 0.1),\n",
        "        intensity=0.1,\n",
        "        effective_radius=0.8,\n",
        "        sersic_index=2.5,\n",
        "    ),\n",
        ")\n",
        "\n",
        "galaxy_1 = ag.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=ag.lp.Sersic(\n",
        "        centre=(0.0, 1.05),\n",
        "        ell_comps=(0.0, 0.1),\n",
        "        intensity=0.1,\n",
        "        effective_radius=0.6,\n",
        "        sersic_index=3.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "galaxies = ag.Galaxies(galaxies=[galaxy_0, galaxy_1])\n",
        "\n",
        "fit_bad = ag.FitImaging(dataset=dataset, galaxies=galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A new fit using these galaxies shows residuals, normalized residuals and chi-squared which are non-zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=fit_bad)\n",
        "\n",
        "fit_plotter.figures_2d(\n",
        "    residual_map=True, normalized_residual_map=True, chi_squared_map=True\n",
        ")\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also note that its likelihood decreases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Quantities__\n",
        "\n",
        "The maximum log likelihood fit contains many 1D and 2D arrays showing the fit.\n",
        "\n",
        "These use the `slim` and `native` API discussed in the previous results tutorial.\n",
        "\n",
        "There is a `model_data`, which is the image of the galaxies we inspected in the previous tutorial blurred with the \n",
        "imaging data's PSF. \n",
        "\n",
        "This is the image that is fitted to the data in order to compute the log likelihood and therefore quantify the \n",
        "goodness-of-fit.\n",
        "\n",
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_data.slim)\n",
        "print(fit.model_data.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous ndarrays showing the goodness of fit: \n",
        "\n",
        " - `residual_map`: Residuals = (Data - Model_Data).\n",
        " - `normalized_residual_map`: Normalized_Residual = (Data - Model_Data) / Noise\n",
        " - `chi_squared_map`: Chi_Squared = ((Residuals) / (Noise)) ** 2.0 = ((Data - Model)**2.0)/(Variances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.residual_map.slim)\n",
        "print(fit.residual_map.native)\n",
        "\n",
        "print(fit.normalized_residual_map.slim)\n",
        "print(fit.normalized_residual_map.native)\n",
        "\n",
        "print(fit.chi_squared_map.slim)\n",
        "print(fit.chi_squared_map.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Figures of Merit__\n",
        "\n",
        "There are single valued floats which quantify the goodness of fit:\n",
        "\n",
        " - `chi_squared`: The sum of the `chi_squared_map`.\n",
        " - `noise_normalization`: The normalizing noise term in the likelihood function \n",
        "    where [Noise_Term] = sum(log(2*pi*[Noise]**2.0)).\n",
        " - `log_likelihood`: The log likelihood value of the fit where [LogLikelihood] = -0.5*[Chi_Squared_Term + Noise_Term]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.chi_squared)\n",
        "print(fit.noise_normalization)\n",
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Quantities__\n",
        "\n",
        "The `FitImaging` object has specific quantities which break down each image of each galaxy:\n",
        "\n",
        " - `model_images_of_galaxies_list`: Model-images of each individual galaxy, which in this example is a model image of \n",
        " the two galaxies in the model. Both images are convolved with the imaging's PSF.\n",
        " \n",
        " - `subtracted_images_of_galaxies_list`: Subtracted images of each individual galaxy, which are the data's image with\n",
        " all other galaxy's model-images subtracted. For example, the first subtracted image has the second galaxy's model image\n",
        " subtracted and therefore is of only the right galaxy's emission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_images_of_galaxies_list[0].slim)\n",
        "print(fit.model_images_of_galaxies_list[1].slim)\n",
        "\n",
        "print(fit.subtracted_images_of_galaxies_list[0].slim)\n",
        "print(fit.subtracted_images_of_galaxies_list[1].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Unmasked Quantities__\n",
        "\n",
        "All of the quantities above are computed using the mask which was used to fit the data.\n",
        "\n",
        "The `FitImaging` can also compute the unmasked blurred image of the galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.unmasked_blurred_image.native)\n",
        "print(fit.unmasked_blurred_image_of_galaxies_list[0].native)\n",
        "print(fit.unmasked_blurred_image_of_galaxies_list[1].native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We can use the `Mask2D` object to mask regions of one of the fit's maps and estimate quantities of it.\n",
        "\n",
        "Below, we estimate the average absolute normalized residuals within a 1.0\" circular mask, which would inform us of\n",
        "how accurate the model fit is in the central regions of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "normalized_residuals = fit.normalized_residual_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.mean(np.abs(normalized_residuals.slim)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Counting__\n",
        "\n",
        "An alternative way to quantify residuals like the galaxy light residuals is pixel counting. For example, we could sum\n",
        "up the number of pixels whose chi-squared values are above 10 which indicates a poor fit to the data.\n",
        "\n",
        "Whereas computing the mean above the average level of residuals, pixel counting informs us how spatially large the\n",
        "residuals extend. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "chi_squared_map = fit.chi_squared_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.sum(chi_squared_map > 10.0))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Outputting Results__\n",
        "\n",
        "You may wish to output certain results to .fits files for later inspection. \n",
        "\n",
        "For example, one could output the galaxy subtracted image of the second galaxy to a .fits file such that\n",
        "we could fit this image again with an independent modeling script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_subtracted_image_2d = fit.subtracted_images_of_galaxies_list[1]\n",
        "galaxy_subtracted_image_2d.output_to_fits(\n",
        "    file_path=path.join(dataset_path, \"galaxy_subtracted_data.fits\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Modeling Results__\n",
        "\n",
        "Modeling uses a non-linear search to fit a model of galaxies to a dataset.\n",
        "\n",
        "It is illustrated in the `modeling` packages of `autogalaxy_workspace`.\n",
        "\n",
        "Modeling results have some specific functionality and use cases, which are described in the `results` packages of\n",
        "`autogalaxy_workspace`,  in particular the `galaxies_fit.py` example script which describes: \n",
        "\n",
        " - `Max Likelihood`: Extract and plot the galaxy models which maximize the likelihood of the fit.\n",
        " - `Samples`, Extract the samples of the non-linear search and inspect specific parameter values.\n",
        " - `Errors`: Makes plots that quantify the errors on the inferred galaxy properties.\n",
        " - `Refitting` Refit specific models from the modeling process to the dataset. \n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "In this tutorial, we saw how to inspect the quality of a model fit using the fit imaging object.\n",
        "\n",
        "If you are modeling galaxies using interferometer data we cover the corresponding fit object in tutorial 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}