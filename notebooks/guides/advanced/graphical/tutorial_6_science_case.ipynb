{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Science Case\n",
        "========================\n",
        "\n",
        "This tutorial shows a realistic science case.\n",
        "\n",
        "We have a dataset containing 10 galaxies, each of which are made of an `Sersic` bulge and `Sersic` disk, where:\n",
        "\n",
        " - The `sersic_index` of each bulge is drawn from a parent hierarchical Gaussian distribution with `mean=4.0`\n",
        " and `sigma=2.0`,\n",
        "\n",
        " - The `sersic_index` parameters of the disks are drawn from an independent parent Gaussian distribution with\n",
        " `mean=1.0` and `sigma=1.0`.\n",
        "\n",
        "This tutorial fits this dataset using expectation propagation (EP) in order to infer the parameters of both parent\n",
        "hierarchical distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autogalaxy as ag\n",
        "import autofit as af\n",
        "from pathlib import Path"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initialization__\n",
        "\n",
        "The following steps repeat all the initial steps performed in the previous tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"imaging\"\n",
        "dataset_sample_name = \"sersic_sersic\"\n",
        "\n",
        "dataset_path = Path(\"dataset\", dataset_type, dataset_label, dataset_sample_name)\n",
        "\n",
        "total_datasets = 5\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = Path(dataset_path, f\"dataset_{dataset_index}\")\n",
        "\n",
        "    dataset_list.append(\n",
        "        ag.Imaging.from_fits(\n",
        "            data_path=Path(dataset_sample_path, \"data.fits\"),\n",
        "            psf_path=Path(dataset_sample_path, \"psf.fits\"),\n",
        "            noise_map_path=Path(dataset_sample_path, \"noise_map.fits\"),\n",
        "            pixel_scales=0.1,\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    mask = ag.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    over_sample_size = ag.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "        grid=dataset.grid,\n",
        "        sub_size_list=[8, 4, 1],\n",
        "        radial_list=[0.3, 0.6],\n",
        "        centre_list=[(0.0, 0.0)],\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "    masked_imaging_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = Path(\"imaging\") / \"graphical\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data.\n",
        "\n",
        "This graphical model creates a non-linear parameter space that has parameters for every galaxy in our sample. In this\n",
        "example, there are 10 galaxies each with their own galaxy model, therefore:\n",
        "\n",
        " - Each galaxy's bulge is a linear parametric linear  `Sersic` with its centre fixed to the input \n",
        " value of (0.0, 0.0) [3 parameters]. \n",
        "\n",
        " - Each galaxy's disk is a linear parametric linear `Sersic` with its centre fixed to the input \n",
        " value of (0.0, 0.0) [3 parameters]. \n",
        "\n",
        " - There are ten galaxies in our graphical model [10 x 8 parameters]. \n",
        "\n",
        "The overall dimensionality of each parameter space fitted separately via EP is therefore N=8.\n",
        "\n",
        "In total, the graph has N = 10 x 8 = 80 free parameters, albeit EP knows the `sersic_index` parameters are drawn from\n",
        "hierarchical distributions and uses this information in the model fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_list = []\n",
        "\n",
        "for model_index in range(total_datasets):\n",
        "    bulge = af.Model(ag.lp_linear.Sersic)\n",
        "    bulge.centre = (0.0, 0.0)\n",
        "\n",
        "    bulge.ell_comps.ell_comps_0 = af.TruncatedGaussianPrior(\n",
        "        mean=0.0, sigma=0.2, lower_limit=-1.0, upper_limit=1.0\n",
        "    )\n",
        "    bulge.ell_comps.ell_comps_1 = af.TruncatedGaussianPrior(\n",
        "        mean=0.0, sigma=0.2, lower_limit=-1.0, upper_limit=1.0\n",
        "    )\n",
        "    bulge.effective_radius = af.TruncatedGaussianPrior(\n",
        "        mean=3.0, sigma=3.0, lower_limit=0.0, upper_limit=10.0\n",
        "    )\n",
        "    bulge.sersic_index = af.TruncatedGaussianPrior(\n",
        "        mean=4.0, sigma=3.0, lower_limit=0.5, upper_limit=10.0\n",
        "    )\n",
        "\n",
        "    disk = af.Model(ag.lp_linear.Sersic)\n",
        "    disk.centre = (0.0, 0.0)\n",
        "    disk.ell_comps.ell_comps_0 = af.TruncatedGaussianPrior(\n",
        "        mean=0.0, sigma=0.3, lower_limit=-1.0, upper_limit=1.0\n",
        "    )\n",
        "    disk.ell_comps.ell_comps_1 = af.TruncatedGaussianPrior(\n",
        "        mean=0.0, sigma=0.3, lower_limit=-1.0, upper_limit=1.0\n",
        "    )\n",
        "    disk.effective_radius = af.TruncatedGaussianPrior(\n",
        "        mean=3.0, sigma=3.0, lower_limit=0.0, upper_limit=10.0\n",
        "    )\n",
        "    disk.sersic_index = af.TruncatedGaussianPrior(\n",
        "        mean=1.0, sigma=3.0, lower_limit=0.5, upper_limit=10.0\n",
        "    )\n",
        "\n",
        "    galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "    model = af.Collection(galaxies=af.Collection(galaxy=galaxy))\n",
        "\n",
        "    model_list.append(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for masked_dataset in masked_imaging_list:\n",
        "    analysis = ag.AnalysisImaging(dataset=masked_dataset, use_jax=True)\n",
        "\n",
        "    analysis_list.append(analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Now we have our `Analysis` classes and graphical model, we can compose our `AnalysisFactor`'s, just like we did in the\n",
        "previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nautilus = af.Nautilus(\n",
        "    path_prefix=Path(\"imaging\") / \"graphical\",\n",
        "    name=\"tutorial_6_science_case\",\n",
        "    n_live=150,\n",
        ")\n",
        "\n",
        "analysis_factor_list = []\n",
        "dataset_index = 0\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "    dataset_name = f\"dataset_{dataset_index}\"\n",
        "    dataset_index += 1\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(\n",
        "        prior_model=model, analysis=analysis, optimiser=nautilus, name=dataset_name\n",
        "    )\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We now compose the hierarchical model components that we fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hierarchical_factor_bulge = af.HierarchicalFactor(\n",
        "    af.TruncatedGaussianPrior,\n",
        "    mean=af.TruncatedGaussianPrior(\n",
        "        mean=3.0, sigma=5.0, lower_limit=0.5, upper_limit=10.0\n",
        "    ),\n",
        "    sigma=af.TruncatedGaussianPrior(\n",
        "        mean=5.0, sigma=5.0, lower_limit=0.0, upper_limit=10.0\n",
        "    ),\n",
        ")\n",
        "\n",
        "hierarchical_factor_disk = af.HierarchicalFactor(\n",
        "    af.TruncatedGaussianPrior,\n",
        "    mean=af.TruncatedGaussianPrior(\n",
        "        mean=3.0, sigma=5.0, lower_limit=0.5, upper_limit=10.0\n",
        "    ),\n",
        "    sigma=af.TruncatedGaussianPrior(\n",
        "        mean=5.0, sigma=5.0, lower_limit=0.0, upper_limit=10.0\n",
        "    ),\n",
        ")\n",
        "\n",
        "for model in model_list:\n",
        "    hierarchical_factor_bulge.add_drawn_variable(\n",
        "        model.galaxies.galaxy.bulge.sersic_index\n",
        "    )\n",
        "    hierarchical_factor_disk.add_drawn_variable(model.galaxies.galaxy.disk.sersic_index)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again combine our `AnalysisFactors` into one, to compose the factor graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factor_graph = af.FactorGraphModel(\n",
        "    *analysis_factor_list, hierarchical_factor_bulge, hierarchical_factor_disk\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The factor graph model `info` attribute shows the complex model we are fitting, including both hierarchical\n",
        "factors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Expectation Propagation__\n",
        "\n",
        "We perform the fit using EP as we did in tutorial 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "laplace = af.LaplaceOptimiser()\n",
        "\n",
        "paths = af.DirectoryPaths(name=Path(path_prefix, \"tutorial_6_science_case\"))\n",
        "\n",
        "factor_graph_result = factor_graph.optimise(\n",
        "    optimiser=laplace, paths=paths, ep_history=af.EPHistory(kl_tol=0.05), max_steps=5\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "The results of the factor graph, using the EP framework and message passing, are contained in the folder \n",
        "`output/graphical/imaging/tutorial_6_science_case`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result)\n",
        "\n",
        "print(factor_graph_result.updated_ep_mean_field.mean_field)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "The MeanField object representing the posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field)\n",
        "print()\n",
        "\n",
        "print(factor_graph_result.updated_ep_mean_field.mean_field.variables)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The logpdf of the posterior at the point specified by the dictionary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# factor_graph_result.updated_ep_mean_field.mean_field(values=None)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the mean with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.mean)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the variance with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.variance)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the s.d./variance**0.5 with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.scale)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "self.updated_ep_mean_field.mean_field[v: Variable] gives the Message/approximation of the posterior for an \n",
        "individual variable of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# factor_graph_result.updated_ep_mean_field.mean_field[\"help\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}