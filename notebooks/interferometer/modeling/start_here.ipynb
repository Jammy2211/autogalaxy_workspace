{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Light Parametric\n",
        "==========================\n",
        "\n",
        "This script fits `Interferometer` dataset of a galaxy with a model where:\n",
        "\n",
        " - The galaxy's light is a parametric `Sersic` bulge and `Exponential` disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We define the \u2018real_space_mask\u2019 which defines the grid the image the galaxy is evaluated using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = ag.Mask2D.circular(\n",
        "    shape_native=(800, 800), pixel_scales=0.05, radius=4.0, sub_size=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the galaxy `Interferometer` dataset `simple__sersic` from .fits files, which we will fit \n",
        "with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"interferometer\", dataset_name)\n",
        "\n",
        "dataset = ag.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.subplot_dirty_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create the `Interferometer` object which is used to fit the model.\n",
        "\n",
        "This includes a `SettingsInterferometer`, which includes the method used to Fourier transform the real-space \n",
        "image of the galaxy to the uv-plane and compare directly to the visiblities. We use a non-uniform fast Fourier \n",
        "transform, which is the most efficient method for interferometer datasets containing ~1-10 million visibilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_dataset = ag.SettingsInterferometer(transformer_class=ag.TransformerNUFFT)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data. In this \n",
        "example we fit a model where:\n",
        "\n",
        " - The galaxy's light is a parametric `Sersic` bulge and `Exponential` disk, the centres of \n",
        " which are aligned [11 parameters].\n",
        " \n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=11.\n",
        "\n",
        "__Coordinates__\n",
        "\n",
        "**PyAutoGalaxy** assumes that the galaxy centre is near the coordinates (0.0\", 0.0\"). \n",
        "\n",
        "If for your dataset the galaxy is not centred at (0.0\", 0.0\"), we recommend that you either: \n",
        "\n",
        " - Reduce your data so that the centre is (`autogalaxy_workspace/*/preprocess`). \n",
        " - Manually override the model priors (`autogalaxy_workspace/*/imaging/modeling/customize/priors.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(ag.lp.Sersic)\n",
        "disk = af.Model(ag.lp.Exponential)\n",
        "bulge.centre = disk.centre\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format.\n",
        "\n",
        "[The `info` below may not display optimally on your computer screen, for example the whitespace between parameter\n",
        "names on the left and parameter priors on the right may lead them to appear across multiple lines. This is a\n",
        "common issue in Jupyter notebooks.\n",
        "\n",
        "The`info_whitespace_length` parameter in the file `config/generag.yaml` in the [output] section can be changed to \n",
        "increase or decrease the amount of whitespace (The Jupyter notebook kernel will need to be reset for this change to \n",
        "appear in a notebook).]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using a non-linear search. In this example, we use the nested sampling algorithm \n",
        "Dynesty (https://dynesty.readthedocs.io/en/latest/).\n",
        "\n",
        "The folders: \n",
        "\n",
        " - `autogalaxy_workspace/*/imaging/modeling/searches`.\n",
        " - `autogalaxy_workspace/*/imaging/modeling/customize`\n",
        "  \n",
        "Give overviews of the  non-linear searches **PyAutoGalaxy** supports and more details on how to customize the\n",
        "model-fit, including the priors on the model. \n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results are stored in the output folder:  \n",
        "\n",
        " `/autogalaxy_workspace/output/imaging/simple__sersic/mass[sie]/unique_identifier`.\n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the path above, the `unique_identifier` appears as a collection of characters, where this identifier is generated \n",
        "based on the model, search and dataset that are used in the fit.\n",
        " \n",
        "An identical combination of model, search and dataset generates the same identifier, meaning that rerunning the\n",
        "script will use the existing results to resume the model-fit. In contrast, if you change the model, search or dataset,\n",
        "a new unique identifier will be generated, ensuring that the model-fit results are output into a separate folder.\n",
        "\n",
        "__Number Of Cores__\n",
        "\n",
        "We include an input `number_of_cores`, which when above 1 means that Dynesty uses parallel processing to sample multiple \n",
        "models at once on your CPU. When `number_of_cores=2` the search will run roughly two times as\n",
        "fast, for `number_of_cores=3` three times as fast, and so on. The downside is more cores on your CPU will be in-use\n",
        "which may hurt the general performance of your computer.\n",
        "\n",
        "You should experiment to figure out the highest value which does not give a noticeable loss in performance of your \n",
        "computer. If you know that your processor is a quad-core processor you should be able to use `number_of_cores=4`. \n",
        "\n",
        "Above `number_of_cores=4` the speed-up from parallelization diminishes greatly. We therefore recommend you do not\n",
        "use a value above this.\n",
        "\n",
        "For users on a Windows Operating system, using `number_of_cores>1` may lead to an error, in which case it should be \n",
        "reduced back to 1 to fix it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"interferometer\", \"modeling\"),\n",
        "    name=\"light[bulge_disk]\",\n",
        "    unique_tag=dataset_name,\n",
        "    nlive=50,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "The `AnalysisInterferometer` object defines the `log_likelihood_function` used by the non-linear search to fit the \n",
        "model to the `Interferometer`dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = ag.AnalysisInterferometer(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "modeling can be a computationally expensive process. When fitting complex models to high resolution datasets \n",
        "run times can be of order hours, days, weeks or even months.\n",
        "\n",
        "Run times are dictated by two factors:\n",
        "\n",
        " - The log likelihood evaluation time: the time it takes for a single `instance` of the model to be fitted to \n",
        "   the dataset such that a log likelihood is returned.\n",
        "\n",
        " - The number of iterations (e.g. log likelihood evaluations) performed by the non-linear search: more complex lens\n",
        "   models require more iterations to converge to a solution.\n",
        "\n",
        "The log likelihood evaluation time can be estimated before a fit using the `profile_log_likelihood_function` method,\n",
        "which returns two dictionaries containing the run-times and information about the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall log likelihood evaluation time is given by the `fit_time` key.\n",
        "\n",
        "For this example, it should be around ~0.25 seconds, which is extremely fast for interferometer modeling. \n",
        "More advanced modeling features (e.g. shapelets, multi Gaussian expansions, pixelizations) have slower log \n",
        "likelihood evaluation times (1-3 seconds), and you should be wary of this when using these features.\n",
        "\n",
        "Feel free to go ahead a print the full `run_time_dict` and `info_dict` to see the other information they contain. The\n",
        "former has a break-down of the run-time of every individual function call in the log likelihood function, whereas the \n",
        "latter stores information about the data which drives the run-time (e.g. number of image-pixels in the mask, the\n",
        "shape of the PSF, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the expected overall run time of the model-fit we multiply the log likelihood evaluation time by an \n",
        "estimate of the number of iterations the non-linear search will perform. \n",
        "\n",
        "Estimating this quantity is more tricky, as it varies depending on the model complexity (e.g. number of parameters)\n",
        "and the properties of the dataset and model being fitted.\n",
        "\n",
        "For this example, we conservatively estimate that the non-linear search will perform ~10000 iterations per free \n",
        "parameter in the model. This is an upper limit, with models typically converging in far fewer iterations.\n",
        "\n",
        "If you perform the fit over multiple CPUs, you can divide the run time by the number of cores to get an estimate of\n",
        "the time it will take to fit the model. However, above ~6 cores the speed-up from parallelization is less efficient and\n",
        "does not scale linearly with the number of cores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We can now begin the model-fit by passing the model and analysis object to the search, which performs a non-linear\n",
        "search to find which models fit the data with the highest likelihood.\n",
        "\n",
        "Checkout the output folder for live outputs of the results of the fit, including on-the-fly visualization of the best \n",
        "fit model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format.\n",
        "\n",
        "[Above, we discussed that the `info_whitespace_length` parameter in the config files could b changed to make \n",
        "the `model.info` attribute display optimally on your computer. This attribute also controls the whitespace of the\n",
        "`result.info` attribute.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Result` object also contains:\n",
        "\n",
        " - The model corresponding to the maximum log likelihood solution in parameter space.\n",
        " - The corresponding maximum log likelihood `Plane` and `FitImaging` objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "plane_plotter = aplt.PlanePlotter(\n",
        "    plane=result.max_log_likelihood_plane,\n",
        "    grid=real_space_mask.derive_grid.unmasked_sub_1,\n",
        ")\n",
        "plane_plotter.subplot()\n",
        "fit_plotter = aplt.FitInterferometerPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_fit_dirty_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result contains the full posterior information of our non-linear search, including all parameter samples, \n",
        "log likelihood values and tools to compute the errors on the lens model. \n",
        "\n",
        "**PyAutoLens** includes visualization tools for plotting this.\n",
        "\n",
        "The plot is labeled with short hand parameter names (e.g. `sersic_index` is mapped to the short hand \n",
        "parameter `n`). These mappings ate specified in the `config/notation.yaml` file and can be customized by users.\n",
        "\n",
        "The superscripts of labels correspond to the name each component was given in the model (e.g. for the `Isothermal`\n",
        "mass its name `mass` defined when making the `Model` above is used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_plotter = aplt.DynestyPlotter(samples=result.samples)\n",
        "search_plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autogalaxy_workspace/*/interferometer/modeling/results.py` for a full description of the result object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}