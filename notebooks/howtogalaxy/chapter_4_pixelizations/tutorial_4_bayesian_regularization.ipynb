{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 4: Bayesian Regularization\n",
        "===================================\n",
        "\n",
        "So far, we have:\n",
        "\n",
        " - Used pixelizations and mappers to map pixelization pixels to image-pixels and visa versa.\n",
        " - Successfully used an inversion to reconstruct a galaxy.\n",
        " - Seen that this reconstruction provides a good fit of the observed image, providing a high likelihood solution.\n",
        "\n",
        "The explanation of *how* an inversion works has so far been overly simplified. You'll have noted the regularization\n",
        "inputs which we have not so far discussed. This will be the topic of this tutorial, and where inversions become more\n",
        "conceptually challenging!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same complex galaxy data as the previous tutorial, where:\n",
        "\n",
        " - The galaxy's bulge is an `Sersic`.\n",
        " - The galaxy's disk is an `Exponential`.\n",
        " - The galaxy's has four star forming clumps which are `Sersic` profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"complex\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Convenience Function__\n",
        "\n",
        "we're going to perform a lot of fits using an `Inversion` this tutorial. This would create a lot of code, so to keep \n",
        "things tidy, I've setup this function which handles it all for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def perform_fit_with_galaxy(dataset, galaxy):\n",
        "    mask = ag.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.0\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    galaxies = ag.Galaxies(galaxies=[galaxy])\n",
        "\n",
        "    return ag.FitImaging(dataset=dataset, galaxies=galaxies)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixelization__\n",
        "\n",
        "Okay, so lets look at our fit from the previous tutorial in more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.Rectangular(shape=(50, 50)),\n",
        "    regularization=ag.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "fit = perform_fit_with_galaxy(dataset=dataset, galaxy=galaxy)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=fit.inversion)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization__\n",
        "\n",
        "The galaxy reconstruction looks pretty good! \n",
        "\n",
        "However, the high quality of this solution was possible because I chose a `coefficient` for the regularization input of\n",
        "1.0. If we reduce this `coefficient` to 0.01, the galaxy reconstruction goes *very* weird."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.Rectangular(shape=(50, 50)),\n",
        "    regularization=ag.reg.Constant(coefficient=0.01),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "no_regularization_fit = perform_fit_with_galaxy(dataset=dataset, galaxy=galaxy)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=no_regularization_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=no_regularization_fit.inversion)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, what is happening here? Why does reducing the `coefficient` do this to our reconstruction? First, we need\n",
        "to understand what regularization actually does!\n",
        "\n",
        "When the inversion reconstructs the galaxy, it does not *only* compute the set of pixelization pixel fluxes that \n",
        "best-fit the image. It also regularizes this solution, whereby it goes to every pixel on the rectangular grid \n",
        "and computes the different between the reconstructed flux values of every pixel with its 4 neighboring pixels. \n",
        "If the difference in flux is large the solution is penalized, reducing its log likelihood. You can think of this as \n",
        "us applying a 'smoothness prior' on the reconstructed galaxy's light.\n",
        "\n",
        "This smoothing adds a 'penalty term' to the log likelihood of an inversion which is the summed difference between the \n",
        "reconstructed fluxes of every pixelization pixel pair multiplied by the `coefficient`. By setting the regularization \n",
        "coefficient to zero, we set this penalty term to zero, meaning that regularization is completely omitted.\n",
        "\n",
        "Why do we need to regularize our solution? We just saw why, if we do not apply this smoothness prior to the galaxy \n",
        "reconstruction, we `over-fit` the image and reconstruct a noisy galaxy with lots of extraneous features. This is what \n",
        "the aliasing chequer-board effect is caused by. If the inversions's sole aim is to maximize the log likelihood, it can \n",
        "do this by fitting *everything* accurately, including the noise.\n",
        "\n",
        "Over-fitting is why regularization is necessary. Solutions like this will completely ruin our attempts to model a \n",
        "galaxy. By smoothing our galaxy reconstruction we ensure it does not over fit noise in the image. \n",
        "\n",
        "So, what happens if we apply a high value for the regularization coefficient?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.Rectangular(shape=(50, 50)),\n",
        "    regularization=ag.reg.Constant(coefficient=100.0),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "high_regularization_fit = perform_fit_with_galaxy(dataset=dataset, galaxy=galaxy)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=high_regularization_fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=high_regularization_fit.inversion)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The figure above shows that we completely remove over-fitting. However, we now fit the image data less poorly,\n",
        "due to the much higher level of smoothing.\n",
        "\n",
        "So, we now understand what regularization is and why it is necessary. There is one nagging question that remains, how \n",
        "do I choose the regularization coefficient value? We can not use the log likelihood, as decreasing the regularization\n",
        "coefficient will always increase the log likelihood, because less smoothing allows the reconstruction to fit \n",
        "the data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Likelihood Without Regularization:\")\n",
        "print(no_regularization_fit.log_likelihood_with_regularization)\n",
        "print(\"Likelihood With Normal Regularization:\")\n",
        "print(fit.log_likelihood_with_regularization)\n",
        "print(\"Likelihood With High Regularization:\")\n",
        "print(high_regularization_fit.log_likelihood_with_regularization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bayesian Evidence__\n",
        "\n",
        "For inversions, we therefore need a different goodness-of-fit measure to choose the appropriate level of regularization. \n",
        "\n",
        "For this, we invoke the `Bayesian Evidence`, which quantifies the goodness of the fit as follows:\n",
        "\n",
        " - It requires that the residuals of the fit are consistent with Gaussian noise (which is the type of noise expected \n",
        " in the imaging data). If this Gaussian pattern is not visible in the residuals, the noise must have been over-fitted\n",
        " by the inversion. The Bayesian evidence will therefore decrease. If the image is fitted poorly due to over smoothing, \n",
        " the residuals will again not appear Gaussian either, again producing a decrease in the Bayesian evidence value.\n",
        "\n",
        " - There can be many solutions which fit the data to the noise level, without over-fitting. To determine the best \n",
        " solutions from these solutions, the Bayesian evidence therefore also quantifies the complexity of the galaxy \n",
        " reconstruction. If an inversion requires many pixels and a low level of regularization to achieve a good fit, the \n",
        " Bayesian evidence will decrease. The evidence penalizes solutions which are complex, which, in a Bayesian sense, are \n",
        " less probable (you may want to look up `Occam`s Razor`).\n",
        "\n",
        "The Bayesian evidence therefore ensures we only invoke a more complex galaxy reconstruction when the data absolutely \n",
        "necessitates it.\n",
        "\n",
        "Lets take a look at the Bayesian evidence of the fits that we performed above, which is accessible from a `FitImaging` \n",
        "object via the `log_evidence` property:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Bayesian Evidence Without Regularization:\")\n",
        "print(no_regularization_fit.log_evidence)\n",
        "print(\"Bayesian Evidence With Normal Regularization:\")\n",
        "print(fit.log_evidence)\n",
        "print(\"Bayesian Evidence With High Regularization:\")\n",
        "print(high_regularization_fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the solution that we could see `by-eye` was the best solution corresponds to the highest log evidence \n",
        "solution.\n",
        "\n",
        "__Non-Linear and Linear__\n",
        "\n",
        "Before we end, lets consider which aspects of an inversion are linear and which are non-linear.\n",
        "\n",
        "The linear part of the inversion is the step that solves for the reconstruct pixelization pixel fluxes, including \n",
        "accounting for the smoothing via regularizaton. We do not have to perform a non-linear search to determine the pixel\n",
        "fluxes or compute the Bayesian evidence discussed above.\n",
        "\n",
        "However, determining the regularization `coefficient` that maximizes the Bayesian log evidence is a non-linear problem \n",
        "that requires a non-linear search. The Bayesian evidence also depends on the grid resolution, which means the \n",
        "pixel-grid's `shape` parameter may also now become dimensions of non linear parameter space (albeit it is common\n",
        "practise for us to simply use the resolution of the image data, or a multiple of this). \n",
        "\n",
        "Nevertheless, these total only 3 non-linear parameters, far fewer than the 20+ that are required when modeling such a\n",
        "complex galaxy using light profiles for every individual clump! \n",
        "\n",
        "Here are a few questions for you to think about.\n",
        "\n",
        " 1) We maximize the log evidence by using simpler galaxy reconstructions. Therefore, decreasing the pixel-grid \n",
        " size should provide a higher log_evidence, provided it still has sufficiently high resolution to fit the image well \n",
        " (and provided that the regularization coefficient is set to an appropriate value). Can you increase the log evidence \n",
        " from the value above by changing these parameters, I've set you up with a code to do so below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.Rectangular(shape=(50, 50)),\n",
        "    regularization=ag.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "fit = perform_fit_with_galaxy(dataset=dataset, galaxy=galaxy)\n",
        "\n",
        "print(\"Previous Bayesian Evidence:\")\n",
        "print(3988.0716851250163)\n",
        "print(\"New Bayesian Evidence:\")\n",
        "print(fit.log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Detailed Description__\n",
        "\n",
        "Below, I provide a more detailed discussion of the Bayesian evidence. It is not paramount that you understand this to\n",
        "use **PyAutoGalaxy**, but I recommend you give it a read to get an intuition for how the evidence works.\n",
        "\n",
        "The Bayesian log evidence quantifies the following 3 aspects of a fit to galaxy imaging data:\n",
        "\n",
        "1) *The quality of the image reconstruction:*  The galaxy reconstruction is a linear inversion which uses the observed\n",
        " values in the image-data to fit it and reconstruct the galaxy. It is in principle able to perfectly reconstruct the\n",
        " image regardless of the image\u2019s noise or the accuracy of the model (e.g. at infinite resolution without\n",
        " regularization). The problem is therefore \u2018ill-posed\u2019 and this is why regularization is necessary.\n",
        "\n",
        " However, this raises the question of what constitutes a \u2018good\u2019 solution? The Bayesian evidence defines this by\n",
        " assuming that the image data consists of independent Gaussian noise in every image pixel. A \u2018good\u2019 solution is one\n",
        " whose chi-squared residuals are consistent with Gaussian noise, producing a reduced chi-squared near 1.0 .Solutions\n",
        " which give a reduced chi squared below 1 are penalized for being overly complex and fitting the image\u2019s noise, whereas\n",
        " solutions with a reduced chi-squared above are penalized for not invoking a more complex galaxy model when the data it\n",
        " is necessary to fit the data bettter. In both circumstances, these penalties reduce the inferred Bayesian evidence!\n",
        "\n",
        "2) *The complexity of the galaxy reconstruction:* The log evidence estimates the number of pixelization pixels that are used \n",
        " to reconstruct the image, after accounting for their correlation with one another due to regularization. Solutions that\n",
        " require fewer correlated galaxy pixels increase the Bayesian evidence. Thus, simpler and less complex galaxy \n",
        " reconstructions are favoured.\n",
        "\n",
        "3) *The signal-to-noise (S/N) of the image that is fitted:* The Bayesian evidence favours models which fit higher S/N\n",
        " realizations of the observed data (where the S/N is determined using the image-pixel variances, e.g. the noise-map). Up \n",
        " to now, all **PyAutoGalaxy** fits assumed fixed variances, meaning that this aspect of the Bayeisan evidence has no impact \n",
        " on the inferred evidence values. \n",
        "   \n",
        " The premise is that whilst increasing the variances of image pixels lowers their S/N values and therefore also\n",
        " decreases the log evidence, doing so may produce a net increase in log evidence. This occurs when the chi-squared \n",
        " values of the image pixels whose variances are increased were initially very high (e.g. they were fit poorly by the \n",
        " model).\n",
        "\n",
        "In summary, the log evidence is maximized for solutions which most accurately reconstruct the highest S/N realization of\n",
        "the observed image, without over-fitting its noise and using the fewest correlated pixelization pixels. By employing \n",
        "this framework throughout, **PyAutoGalaxy** objectively determines the final model following the principles of Bayesian\n",
        "analysis and Occam\u2019s Razor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}