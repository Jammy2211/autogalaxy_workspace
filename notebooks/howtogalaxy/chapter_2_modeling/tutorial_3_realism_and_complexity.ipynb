{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 3: Realism and Complexity\n",
        "==================================\n",
        "\n",
        "In the previous two tutorials, we fitted a fairly basic model: the galaxy's light was a single bulge component.\n",
        "In real observations we know that galaxies are observed to have multiple different morphological structures.\n",
        "\n",
        "In this tutorial, we'll use a more realistic model, which consists of the following light profiles:\n",
        "\n",
        " - An `Sersic` light profile for the galaxy's bulge [7 parameters].\n",
        " - An `Exponential` light profile for the galaxy's disk [6 parameters]\n",
        "\n",
        "This model has 13 free parameters, meaning that the parameter space and likelihood function it defines has a\n",
        "dimensionality of N=13. This is over double the number of parameters and dimensions of the models we fitted in the\n",
        "previous tutorials and in future exercises, we will fit even more complex models with some 13+ parameters.\n",
        "\n",
        "Therefore, take note, as we make our model more realistic, we also make its parameter space more complex, this is\n",
        "an important concept to keep in mind for the remainder of this chapter!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use new galaxying data, where:\n",
        "\n",
        " - The galaxy's bulge is an `Sersic`.\n",
        " - The galaxy's disk is an `Exponential`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We'll create and use a 2.5\" `Mask2D`, which is slightly smaller than the masks we used in previous tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.5\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "Apply adaptive over sampling to ensure the calculation is accurate, you can read up on over-sampling in more detail via \n",
        "the `autogalaxy_workspace/*/guides/over_sampling.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "over_sample_size = ag.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[8, 4, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When plotted, the galaxy's bulge and disk are clearly visible in the centre of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model + Search + Analysis__\n",
        "\n",
        "Now lets fit the dataset using a search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        galaxy=af.Model(\n",
        "            ag.Galaxy, redshift=0.5, bulge=ag.lp.Sersic, disk=ag.lp.Exponential\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtogalaxy\", \"chapter_2\"),\n",
        "    name=\"tutorial_3_realism_and_complexity\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = ag.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "print(\n",
        "    \"The non-linear search has begun running - checkout the autogalaxy_workspace/output/howtogalaxy/chapter_2/tutorial_3_realism_and_complexity\"\n",
        "    \" folder for live output of the results, images and model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Inspection of the `info` summary of the result suggests the model has gone to reasonable values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And lets look at how well the model fits the imaging data, which as we are used to fits the data brilliantly!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Global and Local Maxima__\n",
        "\n",
        "Up to now, all of our non-linear searches have been successes. They find a model that provides a visibly good fit\n",
        "to the data, minimizing the residuals and inferring a high log likelihood value. \n",
        "\n",
        "These solutions are called 'global maxima', they correspond to the highest likelihood regions over all of parameter \n",
        "space. There are no other models in parameter space that would give higher likelihoods, this is the model we want \n",
        "to always infer!\n",
        "\n",
        "However, non-linear searches may not always successfully locate the global maxima models. They may instead infer \n",
        "a 'local maxima', a solution which has a high log likelihood value relative to the models near it in parameter \n",
        "space, but where the log likelihood is significantly below the global maxima solution located somewhere else in \n",
        "parameter space. \n",
        "\n",
        "Why does a non-linear search infer these local maxima solutions? As discussed previously, the search guesses many \n",
        "models over and over, guessing more models in regions of parameter space where previous guesses gave the highest \n",
        "likelihood solutions. The search gradually 'converges' around any solution that gives a higher likelihood than the \n",
        "models nearby it in parameter space. If the search is not thorough enough, it may converge around a solution that \n",
        "appears to give a high likelihood (compared to the models around it) but, as discussed, is only a local maxima over \n",
        "all of parameter space.\n",
        "\n",
        "Inferring such solutions is essentially a failure of our non-linear search and it is something we do not want to\n",
        "happen! Lets infer a local maxima, by reducing the number of live points, `n_live`, nautilus uses to map out \n",
        "parameter space. We are going to use so few that the initial search over parameter space has an extremely low \n",
        "probability of getting close the global maxima, meaning it converges on a local maxima. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtogalaxy\", \"chapter_2\"),\n",
        "    name=\"tutorial_3_realism_and_complexity__local_maxima\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=50,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The non-linear search has begun running - checkout the autogalaxy_workspace/output/3_realism_and_complexity\"\n",
        "    \" folder for live output of the results, images and model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result_local_maxima = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Inspection of the `info` summary of the result suggests certain parameters have gone to different values to the fit\n",
        "performed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_local_maxima.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lats look at the fit to the `Imaging` data, which is clearly worse than our original fit above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=result_local_maxima.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, just to be sure we hit a local maxima, lets compare the maximum log likelihood values of the two results \n",
        "\n",
        "The local maxima value is significantly lower, confirming that our non-linear search simply failed to locate lens \n",
        "models which fit the data better when it searched parameter space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Likelihood of Global Model:\")\n",
        "print(result.max_log_likelihood_fit.log_likelihood)\n",
        "print(\"Likelihood of Local Model:\")\n",
        "print(result_local_maxima.max_log_likelihood_fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "In this example, we intentionally made our non-linear search fail, by using so few live points it had no hope of \n",
        "sampling parameter space thoroughly. For modeling real galaxies we wouldn't do this intentionally, but the risk of \n",
        "inferring a local maxima is still very real, especially as we make our model more complex.\n",
        "\n",
        "Lets think about *complexity*. As we make our model more realistic, we also made it more complex. For this \n",
        "tutorial, our non-linear parameter space went from 7 dimensions to 13. This means there was a much larger *volume* of \n",
        "parameter space to search. As this volume grows, there becomes a higher chance that our non-linear search gets lost \n",
        "and infers a local maxima, especially if we don't set it up with enough live points!\n",
        "\n",
        "At its core, modeling is all about learning how to get a non-linear search to find the global maxima region of \n",
        "parameter space, even when the model is complex. This will be the main theme throughout the rest of this chapter\n",
        "and is the main subject of chapter 3.\n",
        "\n",
        "In the next exercise, we'll learn how to deal with failure and begin thinking about how we can ensure our non-linear \n",
        "search finds the global-maximum log likelihood solution. First, think about the following:\n",
        "\n",
        " 1) When you look at an image of a galaxy, do you get a sense of roughly what values certain model \n",
        " parameters are?\n",
        "    \n",
        " 2) The non-linear search failed because parameter space was too complex. Could we make it less complex, whilst \n",
        " still keeping our model fairly realistic?\n",
        "    \n",
        " 3) The galaxy in this example had only 7 non-linear parameters. Real galaxies may have multiple components (e.g. a \n",
        " disk, bulge, bar, star-forming knot) and there may even be more than 1 galaxy! Do you think there is any hope of \n",
        " us navigating a parameter space if the galaxies contributes 30+ parameters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}