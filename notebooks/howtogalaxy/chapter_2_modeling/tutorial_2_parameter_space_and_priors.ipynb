{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Parameter Space and Priors\n",
        "======================================\n",
        "\n",
        "In the previous tutorial, we used a non-linear search to infer the a model that provided a good fit to simulated\n",
        "imaging data of a galaxy. Now, we will gain deeper intuition of how a non-linear search works.\n",
        "\n",
        "First, lets develop the concept of a 'parameter space'.\n",
        "\n",
        "If mathematics, you will have learnt that we can write a simple function as follows:\n",
        "\n",
        "$f(x) = x^2$\n",
        "\n",
        "In this function, when we input the parameter $x`$ in to the function $f$, it returns a value $f(x)$. The mappings\n",
        "between values of $x$ and $f(x)$ define what we can call the parameter space of this function (and if you remember\n",
        "your math classes, this parameter space is defined by a parabola).\n",
        "\n",
        "A function can of course have multiple parameters:\n",
        "\n",
        "$f(x, y, z) = x + y^2 - z^3$\n",
        "\n",
        "This function has 3 parameters, $x$, $y$ and $z$. The mappings between $x$, $y$ and $z$ and $f(x, y, z)$ define another\n",
        "parameter space, albeit this parameter space now has 3 dimensions. Nevertheless, just like we could plot a parabola to\n",
        "visualize the parameter space $f(x) = x^2$, we could visualize this parameter space as 3 dimensional surface.\n",
        "\n",
        "In the previous tutorial, we discussed how the `AnalysisImaging` class had a `log_likelihood_function` which fitted\n",
        "the imaging data with a model so as to return a log likelihood.\n",
        "\n",
        "This process can be thought of as us computing a likelihood from a function, just like our functions $f(x)$ above.\n",
        "However, the log likelihood function is not something that we can write down analytically as an equation and its\n",
        "behaviour is inherently non-linear. Nevertheless, it is a function, and if we put the same values of model\n",
        "parameters into this function the same value of log likelihood will be returned.\n",
        "\n",
        "Therefore, we can write our log likelihood function as follows, using terms such as $I_{lp}$, $x_{lp}$, $y_{lp}$,\n",
        "as short-hand notation for the parameters of our light profiles.\n",
        "\n",
        "$f(I_{lp}, x_{lp},, y_{lp}, ...) = log(likelihood)$\n",
        "\n",
        "By expressing the likelihood in this way we now have a parameter space! The solutions to this function cannot be written\n",
        "analytically and it is highly complex and non-linear. However, we have already learnt how we use this function to\n",
        "find solutions which give the highest likelihoods; we use a non-linear search!\n",
        "\n",
        "To gain further insight, we can inspect the results of the previous tutorial and its 'Probability density functions' or\n",
        "`PDF' for short. These provide a visual representation of where the non-linear search found the highest likelihood\n",
        "regions of parameter space for each parameter.\n",
        "\n",
        "Navigate to the folder `autogalaxy_workspace/output/howtogalaxy/tutorial_1_non_linear_search/images/searches`\n",
        "and open the `cornerplot.png` figure, where:\n",
        "\n",
        " - The 1D plots of curved lines show, in one dimension, the values of each parameter that gave the highest likelihood\n",
        " solutions.\n",
        "\n",
        " - The 2D plots show contours of how different combinations of parameters gave the highest likelihood. When we see\n",
        "  a curved contour between two parameters, we say that they are 'degenerate', whereby changing both parameters in a\n",
        "  systematic way leads to models that fit the data equally well. As example degeneracy is between the galaxy's\n",
        "  intensity $I_{lp}$ and effective radius $R_{lp}$, which makes sense: making the galaxy brighter and smaller is\n",
        "  similar to making it fainter and bigger!\n",
        "\n",
        "So, how does a non-linear search know where to search parameter space? A parameter, say, the effective radius, could in\n",
        "principle take any value between negative and positive infinity. Something must be telling it to only search certain\n",
        "regions of parameter space with `reasonable` physically plausible values of effective radius (between 0.0\"-30.0\").\n",
        "\n",
        "These are called the 'priors'. Our priors define where we instruct the non-linear search to search parameter space, and\n",
        "throughout these tutorials we will use three types of prior:\n",
        "\n",
        "- UniformPrior: The values of a parameter are randomly drawn between a `lower_limit` and `upper_limit`. For example,\n",
        "the effective radius of ellipitical Sersic profiles typically assumes a uniform prior between 0.0\" and 30.0\".\n",
        "\n",
        "- LogUniformPrior: Like a `UniformPrior` this randomly draws values between a `limit_limit` and `upper_limit`, but the\n",
        "values are drawn from a distribution with base 10. This is used for the `intensity` of a light profile, as the\n",
        "luminosity of galaxies follows a log10 distribution.\n",
        "\n",
        "- GaussianPrior: The values of a parameter are randomly drawn from a Gaussian distribution with a `mean` and width\n",
        " `sigma`. For example, the $y$ and $x$ centre values in a light profile typically assume a mean of 0.0\" and a\n",
        " sigma of 0.3\", indicating that we expect the profile centre to be located near the centre of the image.\n",
        "\n",
        "The default priors of every parameter are provided in the configuration files located at\n",
        "`autogalaxy_workspace/config/priors/`. Each class of models has a config file (e.g. `light_profiles.json`) and they\n",
        "follow the following convention:\n",
        "\n",
        "Sersic:                   <- The name of the `Profile` we are defining the default priors of.\n",
        "  sersic_index:           <- The parameter of the `Profile` we are defining the default priors of.\n",
        "    type: Gaussian        <- The type of prior, in this case a GaussianPrior.\n",
        "    lower_limit: 0.0      <- The lower physical limit allowed for values of this parameter.\n",
        "    upper_limit: \"inf\"    <- The upper physical limit allowed for values of this parameter.\n",
        "    mean: 1.6,            <- The `mean` of the GaussianPrior, telling the search where to sample parameter space.\n",
        "    sigma: 0.01           <- The `sigma` of the GaussianPrior, telling the search how wide to sample this parameter.\n",
        "    gaussian_limits:      <- Ignore these for now.\n",
        "      lower: 0.0\n",
        "      upper: inf\n",
        "    width_modifier:\n",
        "      type: Relative\n",
        "      value: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same data as the previous tutorial, where:\n",
        "\n",
        " - The galaxy's `LightProfile` is an `Sersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "we'll create and use a 3.0\" `Mask2D` again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Prior Customization__\n",
        "\n",
        "To change the priors on specific parameters, we create our galaxy models and use **PyAutoFit** to set new priors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy = af.Model(ag.Galaxy, redshift=1.0, bulge=ag.lp.Sersic)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These two lines change the centre of the galaxy's light distribution to UniformPriors around the coordinates \n",
        "(-0.1\", 0.1\"). For real modeling, this might be done by visually inspecting the centre of emission of the galaxy's\n",
        "light.\n",
        "\n",
        "The word `bulge` corresponds to the word we used when setting up the `Model` above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy.bulge.centre_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "galaxy.bulge.centre_1 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets also change the prior on the galaxy's sersic_index to a `GaussianPrior` centred on 4.0. \n",
        "For real galaxy modeling, this might be done by understanding before that the galaxy has an early-type morphology, \n",
        "which means it should have a Sersic index close to 4.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy.bulge.sersic_index = af.GaussianPrior(mean=4.0, sigma=1.0, lower_limit=0.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also customize the galaxy effective radius, for example a prior reducing its upper limit means we believe it \n",
        "is compact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy.bulge.effective_radius = af.UniformPrior(lower_limit=0.0, upper_limit=2.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again combine our model components into a `Collection`, which will use the objects with these updated priors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, including the updated priors specified above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can now fit this custom model with a search like we did in tutorial 1. \n",
        "\n",
        "If you look at the `model.info` file in the output folder of the non-linear search, you'll see that certain priors \n",
        "have been updated to the priors we set above.\n",
        "\n",
        "__Number Of Cores__\n",
        "\n",
        "When setting up nautilus, we include a new input `number_of_cores=1`. The non-linear search can use parallel processing \n",
        "to sample multiple models at once on your CPU. When `number_of_cores=2` the search will run roughly two times as\n",
        "fast, for `number_of_cores=3` three times as fast, and so on. The downside is more cores on your CPU will be in-use\n",
        "which may hurt the general performance of your computer.\n",
        "\n",
        "You should experiment to figure out the highest value which does not give a noticeable loss in performance of your \n",
        "computer. If you know that your processor is a quad-core processor you should be able to use `number_of_cores=4`, \n",
        "and even higher end processors can potentially use even higher values. For users on a Windows Operating system,\n",
        "using `number_of_cores>1` may lead to an error, in which case it should be reduced back to 1 to fix it.\n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the previous tutorial, we discussed how a unique tag is generated based on the model fitted and search used. When\n",
        "fitting a single dataset this tag is sufficient, however in the future we may want to fit multiple datasets with\n",
        "the same model using the same search. \n",
        "\n",
        "We can make the unique identifier use the name of the dataset as an additional criteria to generate the unique string, \n",
        "by passing the `dataset_name` to the `unique_tag` of the search, as shown below. This is good practise in general\n",
        "and is something we will always adopt when performing model-fits from here on.\n",
        "\n",
        "The unique tag also places an additional folder after the `path_prefix`. Although this is not necessary to keep results\n",
        "separate (as each model-fit has its own unique tag) it makes the results more readable in the output folder, as you\n",
        "can see which data each model was fitted too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtogalaxy\", \"chapter_2\"),\n",
        "    name=\"tutorial_2_custom_priors\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=80,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = ag.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "print(\n",
        "    \"The non-linear search has begun running - checkout the autogalaxy_workspace/output/howtogalaxy/chapter_2/tutorial_2_parameter_space_and_priors\"\n",
        "    \" folder for live output of the results, images and model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "A concise readable summary of the results is given by printing its `info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use the result to plot the maximum likelihood fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "This tutorial had some pretty difficult concepts to wrap your head around. However, I cannot emphasize \n",
        "enough how important it is that you develop an intuition for non-linear searches and the notion of a non-linear \n",
        "parameter space. Becoming good at modeling is all being able to navigate a complex, degenerate and highly \n",
        "non-linear parameter space! Luckily, we're going to keep thinking about this in the next set of tutorials, so if \n",
        "you're not feeling too confident yet, you will be soon!\n",
        "\n",
        "Before continuing to the next tutorial, I want you think about whether anything could go wrong when we search a \n",
        "non-linear parameter space. Is it possible that we do not find the highest log likelihood model? Why might this be?\n",
        "\n",
        "Try and list 3 reasons why this might happen. In the next tutorial, we'll learn about just that, failure!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}