{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Same Wavelength\n",
        "=========================\n",
        "\n",
        "This script fits a multiple `Imaging` datasets observed at the same wavelength of a galaxy with a\n",
        "model where:\n",
        "\n",
        " - The galaxy's light is a linear parametric `Sersic` bulge and `Exponential` disk.\n",
        "\n",
        "This script demonstrates how PyAutoGalaxy's multi-dataset modeling tools can also simultaneously analyse datasets\n",
        "observed at the same wavelength.\n",
        "\n",
        "An example use case might be analysing undithered HST images before they are combined via the multidrizzing process,\n",
        "to remove correlated noise in the data.\n",
        "\n",
        "This is an advanced script and assumes previous knowledge of the core **PyAutoGalaxy** API for galaxy modeling. Thus,\n",
        "certain parts of code are not documented to ensure the script is concise.\n",
        "\n",
        "TODO: NEED TO INCLUDE DIFFERENT POINTING / CENTERINGS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Scales__\n",
        "\n",
        "If observed at the same wavelength, it is likely the datasets have the same pixel-scale.\n",
        "\n",
        "Nevertheless, we specify this as a list as there could be an exception."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales_list = [0.1, 0.1]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot each multi-wavelength galaxy dataset, using a list of their waveband colors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"multi\"\n",
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"same_wavelength\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_name)\n",
        "\n",
        "dataset_list = [\n",
        "    ag.Imaging.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"image_{i}.fits\"),\n",
        "        psf_path=path.join(dataset_path, f\"psf_{i}.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"noise_map_{i}.fits\"),\n",
        "        pixel_scales=pixel_scales,\n",
        "    )\n",
        "    for i, pixel_scales in enumerate(pixel_scales_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "The model-fit requires a `Mask2D` defining the regions of the image we fit the galaxy model to the data, which we define\n",
        "and use to set up the `Imaging` object that the galaxy model fits.\n",
        "\n",
        "For multi-wavelength galaxy modeling, we use the same mask for every dataset whenever possible. This is not\n",
        "absolutely necessary, but provides a more reliable analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_list = [\n",
        "    ag.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "    for dataset in dataset_list\n",
        "]\n",
        "\n",
        "\n",
        "dataset_list = [\n",
        "    dataset.apply_mask(mask=mask) for imaging, mask in zip(dataset_list, mask_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We create an `Analysis` object for every dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [ag.AnalysisImaging(dataset=dataset) for dataset in dataset_list]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By summing this list of analysis objects, we create an overall `CombinedAnalysis` which we can use to fit the \n",
        "multi-wavelength imaging data, where:\n",
        "\n",
        " - The log likelihood function of this summed analysis class is the sum of the log likelihood functions of each \n",
        " individual analysis objects (e.g. the fit to each separate waveband).\n",
        "\n",
        " - The summing process ensures that tasks such as outputting results to hard-disk, visualization, etc use a \n",
        " structure that separates each analysis and therefore each dataset.\n",
        " \n",
        " - Next, we will use this combined analysis to parameterize a model where certain galaxy parameters vary across\n",
        " the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = sum(analysis_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can parallelize the likelihood function of these analysis classes, whereby each evaluation is performed on a \n",
        "different CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis.n_cores = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our galaxy model using `Model` objects, which represent the galaxies we fit to our data. In this \n",
        "example we fit a galaxy model where:\n",
        "\n",
        " - The galaxy's bulge is a linear parametric `Sersic` bulge [6 parameters]. \n",
        " \n",
        " - The galaxy's disk is a linear parametric `Exponential`disk [5 parameters]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(ag.lp_linear.Sersic)\n",
        "disk = af.Model(ag.lp_linear.Exponential)\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: Extend code below to vary the dataset centering / pointing across the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# analysis = analysis.with_free_parameters(model.galaxies.source.bulge.intensity)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using a non-linear search. In this example, we use the nested sampling algorithm \n",
        "Nautilus (https://nautilus.readthedocs.io/en/latest/).\n",
        "\n",
        "A full description of the settings below is given in the beginner modeling scripts, if anything is unclear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"multi\", \"modeling\"),\n",
        "    name=\"same_wavelength\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_list = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by this model-fit is a list of `Result` objects, because we used a combined analysis.\n",
        "Each result corresponds to each analysis, and therefore corresponds to the model-fit at that wavelength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_list[0].max_log_likelihood_instance)\n",
        "print(result_list[1].max_log_likelihood_instance)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting each result's galaxies shows that the source appears different, owning to its different intensities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for result in result_list:\n",
        "    galaxies_plotter = aplt.GalaxiesPlotter(\n",
        "        galaxies=result.max_log_likelihood_galaxies, grid=result.grids.lp\n",
        "    )\n",
        "    galaxies_plotter.subplot_galaxies()\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` object still has the dimensions of the overall non-linear search (in this case N=15). \n",
        "\n",
        "Therefore, the samples is identical in every result object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.NestPlotter(samples=result_list.samples)\n",
        "plotter.corner_cornerpy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autogalaxy_workspace/*/imaging/results` for a full description of analysing results in **PyAutoGalaxy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}