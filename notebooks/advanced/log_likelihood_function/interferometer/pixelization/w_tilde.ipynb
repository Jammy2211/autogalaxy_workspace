{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: W Tilde__\n",
        "\n",
        "This script describes how a pixelization can be computed using a different linear algebra calculation, but\n",
        "one which produces an identical likelihood at the end.\n",
        "\n",
        "This is called the `w_tilde` formalism, and for interferometer datasets it avoids storing the `operated_mapping_matrix`\n",
        "in memory, meaning that in the regime of 1e6 or more visibilities this extremely large matrix does not need to be\n",
        "stored in memory.\n",
        "\n",
        "This can make the likelihood function significantly faster, for example with speed ups of hundreds of times or more\n",
        "for tens or millions of visibilities. In fact, the run time does not scale with the number of visibilities at all,\n",
        "meaning datasets of any size can be fitted in seconds.\n",
        "\n",
        "It directly follows on from the `pixelization/log_likelihood_function.py` notebook and you should read through that\n",
        "script before reading this script.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "You must read through the following likelihood functions first:\n",
        "\n",
        " - `pixelization/log_likelihood_function.py` the likelihood function for a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `pixelization/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = ag.Mask2D.circular(\n",
        "    shape_native=(8, 8), pixel_scales=0.05, radius=4.0\n",
        ")\n",
        "\n",
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"interferometer\", dataset_name)\n",
        "\n",
        "dataset = ag.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=ag.TransformerDFT,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W Tilde__\n",
        "\n",
        "We now compute the `w_tilde` matrix.\n",
        "\n",
        "The `w_tilde` matrix is applied to the `curvature_matrix`, and allows us to efficiently compute the curvature matrix\n",
        "without computing the `transformed_mapping_matrix` matrix. \n",
        "\n",
        "The functions used to do this has been copy and pasted from the `inversion` module of PyAutoArray source code below,\n",
        "so you can see the calculation in full detail.\n",
        "\n",
        "REMINDER: for the `real_space_mask` above with shape (800, 800) the `w_tilde` matrix will TAKE A LONG\n",
        "TIME TO COMPUTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray import numba_util\n",
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real: np.ndarray,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    grid_radians_slim: np.ndarray,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    The matrix w_tilde is a matrix of dimensions [image_pixels, image_pixels] that encodes the NUFFT of every pair of\n",
        "    image pixels given the noise map. This can be used to efficiently compute the curvature matrix via the mappings\n",
        "    between image and source pixels, in a way that omits having to perform the NUFFT on every individual source pixel.\n",
        "    This provides a significant speed up for inversions of interferometer datasets with large number of visibilities.\n",
        "\n",
        "    The limitation of this matrix is that the dimensions of [image_pixels, image_pixels] can exceed many 10s of GB's,\n",
        "    making it impossible to store in memory and its use in linear algebra calculations extremely. The method\n",
        "    `w_tilde_preload_interferometer_from` describes a compressed representation that overcomes this hurdles. It is\n",
        "    advised `w_tilde` and this method are only used for testing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    noise_map_real\n",
        "        The real noise-map values of the interferometer data.\n",
        "    uv_wavelengths\n",
        "        The wavelengths of the coordinates in the uv-plane for the interferometer dataset that is to be Fourier\n",
        "        transformed.\n",
        "    grid_radians_slim\n",
        "        The 1D (y,x) grid of coordinates in radians corresponding to real-space mask within which the image that is\n",
        "        Fourier transformed is computed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        A matrix that encodes the NUFFT values between the noise map that enables efficient calculation of the curvature\n",
        "        matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    w_tilde = np.zeros((grid_radians_slim.shape[0], grid_radians_slim.shape[0]))\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            y_offset = grid_radians_slim[i, 1] - grid_radians_slim[j, 1]\n",
        "            x_offset = grid_radians_slim[i, 0] - grid_radians_slim[j, 0]\n",
        "\n",
        "            for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                w_tilde[i, j] += noise_map_real[vis_1d_index] ** -2.0 * np.cos(\n",
        "                    2.0\n",
        "                    * np.pi\n",
        "                    * (\n",
        "                        y_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                        + x_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            w_tilde[j, i] = w_tilde[i, j]\n",
        "\n",
        "    return w_tilde\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compute the `w_tilde` matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w_tilde = w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real=np.array(dataset.noise_map.real),\n",
        "    uv_wavelengths=np.array(dataset.uv_wavelengths),\n",
        "    grid_radians_slim=np.array(dataset.grid.in_radians),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `w_tilde` matrix is applied directly to the `mapping_matrix` to compute the `curvature_matrix`.\n",
        "\n",
        "Below, we perform the likelihood function steps described in the `pixelization/log_likelihood_function.py` script,\n",
        "to create the `mapping_matrix` we will apply the `w_tilde` matrix to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.Rectangular(shape=(30, 30)),\n",
        "    regularization=ag.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "grid_rectangular = ag.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=dataset.grids.pixelization\n",
        ")\n",
        "\n",
        "mapper_grids = ag.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = ag.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapping_matrix = ag.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=mapper.pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix__\n",
        "\n",
        "We can now compute the `curvature_matrix` using the `w_tilde` matrix and `mapping_matrix`, which amazingly uses\n",
        "simple matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def curvature_matrix_via_w_tilde_from(\n",
        "    w_tilde: np.ndarray, mapping_matrix: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns the curvature matrix `F` (see Warren & Dye 2003) from `w_tilde`.\n",
        "\n",
        "    The dimensions of `w_tilde` are [image_pixels, image_pixels], meaning that for datasets with many image pixels\n",
        "    this matrix can take up 10's of GB of memory. The calculation of the `curvature_matrix` via this function will\n",
        "    therefore be very slow, and the method `curvature_matrix_via_w_tilde_curvature_preload_imaging_from` should be used\n",
        "    instead.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    w_tilde\n",
        "        A matrix of dimensions [image_pixels, image_pixels] that encodes the convolution or NUFFT of every image pixel\n",
        "        pair on the noise map.\n",
        "    mapping_matrix\n",
        "        The matrix representing the mappings between sub-grid pixels and pixelization pixels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        The curvature matrix `F` (see Warren & Dye 2003).\n",
        "    \"\"\"\n",
        "\n",
        "    return np.dot(mapping_matrix.T, np.dot(w_tilde, mapping_matrix))\n",
        "\n",
        "\n",
        "curvature_matrix = curvature_matrix_via_w_tilde_from(\n",
        "    w_tilde=w_tilde, mapping_matrix=mapping_matrix\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you compare the `curvature_matrix` computed using the `w_tilde` matrix to the `curvature_matrix` computed using the\n",
        "`operated_mapping_matrix` matrix in the other example scripts, you'll see they are identical.\n",
        "\n",
        "__Data Vector__\n",
        "\n",
        "The `data_vector` was computed in the `pixelization/log_likelihood_function.py` script using \n",
        "the `transformed_mapping_matrix`.\n",
        "\n",
        "Fortunately, there is also an easy way to compute the `data_vector` which bypasses the need to compute the\n",
        "`transformed_mapping_matrix` matrix, again using simple matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = np.dot(mapping_matrix.T, dataset.w_tilde.dirty_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction__\n",
        "\n",
        "The `reconstruction` is computed using the `curvature_matrix` and `data_vector` as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_matrix = ag.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Step: Chi Squared__\n",
        "\n",
        "In the `pixelization/log_likelihood_function.py` example the mapped reconstructed visibilities were another quantity \n",
        "computed which used the `transformed_mapping_matrix` matrix, which is another step that must skip computing this matrix.\n",
        "\n",
        "The w-tilde matrix again provides a trick which skips the need to compute the `transformed_mapping_matrix` matrix,\n",
        "with the code for this shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mapping_matrix.shape)\n",
        "print(w_tilde.shape)\n",
        "\n",
        "chi_squared_term_1 = np.linalg.multi_dot(\n",
        "    [\n",
        "        mapping_matrix.T,  # NOTE: shape = (N, )\n",
        "        w_tilde,  # NOTE: shape = (N, N)\n",
        "        mapping_matrix,\n",
        "    ]\n",
        ")\n",
        "\n",
        "chi_squared_term_2 = -np.multiply(2.0, np.dot(mapping_matrix.T, dataset.w_tilde.dirty_image)) # Need to double check dirty_image is the right input.\n",
        "\n",
        "chi_squared = chi_squared_term_1 + chi_squared_term_2\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood__\n",
        "\n",
        "Finally, we verify that the log likelihood computed using the `curvature_matrix` and `data_vector` computed using the\n",
        "`w_tilde` matrix is identical to the log likelihood computed using the `operated_mapping_matrix` matrix in the\n",
        "other example scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "\n",
        "noise_normalization_real = np.sum(np.log(2 * np.pi * dataset.noise_map.real**2.0))\n",
        "noise_normalization_imag = np.sum(np.log(2 * np.pi * dataset.noise_map.imag**2.0))\n",
        "noise_normalization = noise_normalization_real + noise_normalization_imag\n",
        "\n",
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}