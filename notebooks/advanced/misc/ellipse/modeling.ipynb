{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling\n",
        "========\n",
        "\n",
        "This guide shows how to perform ellipse fitting modeling on data using a non-linear search, including visualizing and\n",
        "interpreting its results.\n",
        "\n",
        "__Fit__\n",
        "\n",
        "The non-linear search in this example calls a `log_likelihood_function` using the `Analysis` class many times, in\n",
        "order to determine ellipse parameters and therefore overall distribution of ellipses that best-fit the data.\n",
        "\n",
        "The `log_likelihood_function` and how the ellipses are used to fit the data are described in the `fit.py` script,\n",
        "which you should read first in order to better understand how ellipse fitting works.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autogalaxy_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutoriag.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoGalaxy**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The guide `guides/units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses.\n",
        "\n",
        "__Data Structures__\n",
        "\n",
        "Quantities inspected in this example script use **PyAutoGalaxy** bespoke data structures for storing arrays, grids,\n",
        "vectors and other 1D and 2D quantities. These use the `slim` and `native` API to toggle between representing the\n",
        "data in 1D numpy arrays or high dimension numpy arrays.\n",
        "\n",
        "This tutorial will only use the `slim` properties which show results in 1D numpy arrays of\n",
        "shape [total_unmasked_pixels]. This is a slimmed-down representation of the data in 1D that contains only the\n",
        "unmasked data points\n",
        "\n",
        "These are documented fully in the `autogalaxy_workspace/*/guides/data_structures.ipynb` guide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data__\n",
        "\n",
        "We we begin by loading the galaxy dataset `simple` from .fits files, which is the dataset we will use to demonstrate \n",
        "ellipse fitting.\n",
        "\n",
        "This uses the `Imaging` object used in other examples.\n",
        "\n",
        "Ellipse fitting does not use the Point Spread Function (PSF) of the dataset, so we do not need to load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"ellipse\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the `ImagingPlotter` to plot the image and noise-map of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.figures_2d(data=True, noise_map=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ImagingPlotter` also contains a subplot which plots all these properties simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We now mask the data, so that regions where there is no signal (e.g. the edges) are omitted from the fit.\n",
        "\n",
        "We use a `Mask2D` object, which for this example is 4.0\" circular mask.\n",
        "\n",
        "For ellipse fitting, the mask radius defines the region of the image that the ellipses are fitted over. We therefore\n",
        "define the `mask_radius` as a variable which is used below to define the sizes of the ellipses in the model fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 5.0\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now combine the imaging dataset with the mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the image with the mask applied, where the image automatically zooms around the mask to make the galaxy\n",
        "appear bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.set_title(\"Image Data With Mask Applied\")\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mask is also used to compute a `Grid2D`, where the (y,x) arc-second coordinates are only computed in unmasked\n",
        "pixels within the masks' circle.\n",
        "\n",
        "As shown in the previous overview example, this grid will be used to perform galaxying calculations when fitting the\n",
        "data below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=dataset.grid)\n",
        "grid_plotter.set_title(\"Grid2D of Masked Dataset\")\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Composition__\n",
        "\n",
        "The API below for composing a model uses the `Model` and `Collection` objects, which are imported from the \n",
        "parent project **PyAutoFit** \n",
        "\n",
        "The API is fairly self explanatory and is straight forward to extend, for example adding more ellipses\n",
        "to the galaxy.\n",
        "\n",
        "Ellipse fitting fits ellispes of increasing size to the data, one after another, with the properties of each ellipse\n",
        "as a function of size being the main results of the model-fit.\n",
        "\n",
        "We therefore compose a model consistent of a single ellise to demonstrate this fitting process, and then towards\n",
        "the end of the script we will extend the model to fit multiple ellipses.\n",
        "\n",
        "The model is composed of 1 ellipses as follows:\n",
        "\n",
        "1) The ellipse has a fixed sizes that is input manually. When multiple ellipses are fitted, this size will \n",
        "   incrementally grow in size in order to cover the entire galaxy.\n",
        "\n",
        "2) The centre and elliptical components of the ellipse are free, meaning that the model has N=4 free parameters.\n",
        "\n",
        "The model composition below uses a list even though there is one ellipse, as this format allows us to fit\n",
        "multiple ellipses in the model-fit at once, albeit its rare we would want to do this.\n",
        "\n",
        "__Model Cookbook__\n",
        "\n",
        "A full description of model composition is provided by the model cookbook: \n",
        "\n",
        "https://pyautogalaxy.readthedocs.io/en/latest/general/model_cookbook.html\n",
        "\n",
        "__Coordinates__\n",
        "\n",
        "The model fitting default settings assume that the galaxy centre is near the coordinates (0.0\", 0.0\"). \n",
        "\n",
        "If for your dataset the galaxy is not centred at (0.0\", 0.0\"), we recommend that you either: \n",
        "\n",
        " - Reduce your data so that the centre is (`autogalaxy_workspace/*/preprocess`). \n",
        " - Manually override the model priors (`autogalaxy_workspace/*/modeling/imaging/customize/priors.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ellipse = af.Model(ag.Ellipse)\n",
        "\n",
        "ellipse.centre.centre_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "ellipse.centre.centre_1 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "\n",
        "ellipse.ell_comps.ell_comps_0 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "ellipse.ell_comps.ell_comps_1 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "\n",
        "ellipse.major_axis = 0.3\n",
        "\n",
        "model = af.Collection(ellipses=[ellipse])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format.\n",
        "\n",
        "[The `info` below may not display optimally on your computer screen, for example the whitespace between parameter\n",
        "names on the left and parameter priors on the right may lead them to appear across multiple lines. This is a\n",
        "common issue in Jupyter notebooks.\n",
        "\n",
        "The`info_whitespace_length` parameter in the file `config/generag.yaml` in the [output] section can be changed to \n",
        "increase or decrease the amount of whitespace (The Jupyter notebook kernel will need to be reset for this change to \n",
        "appear in a notebook).]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using a non-linear search. \n",
        "\n",
        "This example uses the nested sampling algorithm  Dynesty (https://dynesty.readthedocs.io/en/stable/), which extensive \n",
        "testing has revealed gives the most accurate and efficient modeling results for ellipse fitting.\n",
        "\n",
        "Dynesty has one main setting that trades-off accuracy and computational run-time, the number of `live_points`. \n",
        "A higher number of live points gives a more accurate result, but increases the run-time. A lower value may give \n",
        "less reliable modeling (e.g. the fit may infer a local maxima), but is faster. \n",
        "\n",
        "The suitable value depends on the model complexity whereby models with more parameters require more live points. \n",
        "The default value of 200 is sufficient for the vast majority of ellipse fitting problems. Lower values often given \n",
        "reliable results though, and speed up the run-times. \n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the path above, the `unique_identifier` appears as a collection of characters, where this identifier is generated \n",
        "based on the model, search and dataset that are used in the fit.\n",
        "\n",
        "An identical combination of model and search generates the same identifier, meaning that rerunning the script will use \n",
        "the existing results to resume the model-fit. In contrast, if you change the model or search, a new unique identifier \n",
        "will be generated, ensuring that the model-fit results are output into a separate folder.\n",
        "\n",
        "We additionally want the unique identifier to be specific to the dataset fitted, so that if we fit different datasets\n",
        "with the same model and search results are output to a different folder. We achieve this below by passing \n",
        "the `dataset_name` to the search's `unique_tag`.\n",
        "\n",
        "__Number Of Cores__\n",
        "\n",
        "We include an input `number_of_cores`, which when above 1 means that Nautilus uses parallel processing to sample multiple \n",
        "models at once on your CPU. When `number_of_cores=2` the search will run roughly two times as\n",
        "fast, for `number_of_cores=3` three times as fast, and so on. The downside is more cores on your CPU will be in-use\n",
        "which may hurt the general performance of your computer.\n",
        "\n",
        "You should experiment to figure out the highest value which does not give a noticeable loss in performance of your \n",
        "computer. If you know that your processor is a quad-core processor you should be able to use `number_of_cores=4`. \n",
        "\n",
        "Above `number_of_cores=4` the speed-up from parallelization diminishes greatly. We therefore recommend you do not\n",
        "use a value above this.\n",
        "\n",
        "For users on a Windows Operating system, using `number_of_cores>1` may lead to an error, in which case it should be \n",
        "reduced back to 1 to fix it.\n",
        "\n",
        "__Parallel Script__\n",
        "\n",
        "Depending on the operating system (e.g. Linux, Mac, Windows), Python version, if you are running a Jupyter notebook \n",
        "and other factors, this script may not run a successful parallel fit (e.g. running the script \n",
        "with `number_of_cores` > 1 will produce an error). It is also common for Jupyter notebooks to not run in parallel \n",
        "correctly, requiring a Python script to be run, often from a command line terminal.\n",
        "\n",
        "To fix these issues, the Python script needs to be adapted to use an `if __name__ == \"__main__\":` API, as this allows\n",
        "the Python `multiprocessing` module to allocate threads and jobs correctly. An adaptation of this example script \n",
        "is provided at `autolens_workspace/scripts/modeling/imaging/customize/parallel.py`, which will hopefully run \n",
        "successfully in parallel on your computer!\n",
        "\n",
        "Therefore if paralellization for this script doesn't work, check out the `parallel.py` example. You will need to update\n",
        "all scripts you run to use the this format and API. \n",
        "\n",
        "__Iterations Per Update__\n",
        "\n",
        "Every N iterations, the non-linear search outputs the current results to the folder `autogalaxy_workspace/output`,\n",
        "which includes producing visualization. \n",
        "\n",
        "Depending on how long it takes for the model to be fitted to the data (see discussion about run times below), \n",
        "this can take up a large fraction of the run-time of the non-linear search.\n",
        "\n",
        "For this fit, the fit is very fast, thus we set a high value of `iterations_per_update=10000` to ensure these updates\n",
        "so not slow down the overall speed of the model-fit. \n",
        "\n",
        "**If the iteration per update is too low, the model-fit may be significantly slowed down by the time it takes to\n",
        "output results and visualization frequently to hard-disk. If your fit is consistent displaying a log saying that it\n",
        "is outputting results, try increasing this value to ensure the model-fit runs efficiently.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"ellipse\"),\n",
        "    name=f\"fit_start\",\n",
        "    unique_tag=dataset_name,\n",
        "    sample=\"rwalk\",\n",
        "    n_live=50,\n",
        "    number_of_cores=4,\n",
        "    iterations_per_update=10000,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We next create an `AnalysisEllipse` object, which can be given many inputs customizing how the model is fitted to the \n",
        "data (in this example they are omitted for simplicity).\n",
        "\n",
        "Internally, this object defines the `log_likelihood_function` used by the non-linear search to fit the model to \n",
        "the `Imaging` dataset. \n",
        "\n",
        "It is not vital that you as a user understand the details of how the `log_likelihood_function` fits a model to \n",
        "data, but interested readers can find a step-by-step guide of the likelihood \n",
        "function at ``autogalaxy_workspace/*/imaging/log_likelihood_function`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = ag.AnalysisEllipse(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "Modeling can be a computationally expensive process. When fitting complex models to high resolution datasets \n",
        "run times can be of order hours, days, weeks or even months.\n",
        "\n",
        "Run times are dictated by two factors:\n",
        "\n",
        " - The log likelihood evaluation time: the time it takes for a single `instance` of the model to be fitted to \n",
        "   the dataset such that a log likelihood is returned.\n",
        "\n",
        " - The number of iterations (e.g. log likelihood evaluations) performed by the non-linear search: more complex\n",
        "   models require more iterations to converge to a solution.\n",
        "\n",
        "The log likelihood evaluation time can be estimated before a fit using the `profile_log_likelihood_function` method,\n",
        "which returns two dictionaries containing the run-times and information about the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall log likelihood evaluation time is given by the `fit_time` key.\n",
        "\n",
        "For this example, it is ~0.04 seconds, which is extremely fast for modeling. For higher resolution datasets ellipse\n",
        "fitting can slow down to a likelihood evaluation time of order 0.5 - 1.0 second, which is still reasonably fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the expected overall run time of the model-fit we multiply the log likelihood evaluation time by an \n",
        "estimate of the number of iterations the non-linear search will perform. \n",
        "\n",
        "Estimating this quantity is more tricky, as it varies depending on the model complexity (e.g. number of parameters)\n",
        "and the properties of the dataset and model being fitted.\n",
        "\n",
        "For this example, we conservatively estimate that the non-linear search will perform ~10000 iterations per free \n",
        "parameter in the model. This is an upper limit, with models typically converging in far fewer iterations.\n",
        "\n",
        "If you perform the fit over multiple CPUs, you can divide the run time by the number of cores to get an estimate of\n",
        "the time it will take to fit the model. Parallelization with Nautilus scales well, it speeds up the model-fit by the \n",
        "`number_of_cores` for N < 8 CPUs and roughly `0.5*number_of_cores` for N > 8 CPUs. This scaling continues \n",
        "for N> 50 CPUs, meaning that with super computing facilities you can always achieve fast run times!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We can now begin the model-fit by passing the model and analysis object to the search, which performs a non-linear\n",
        "search to find which models fit the data with the highest likelihood.\n",
        "\n",
        "Checkout the output folder for live outputs of the results of the fit, including on-the-fly visualization of the best \n",
        "fit model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output Folder__\n",
        "\n",
        "Now this is running you should checkout the `autogalaxy_workspace/output` folder. This is where the results of the \n",
        "search are written to hard-disk (in the `start_here` folder), where all outputs are human readable (e.g. as .json,\n",
        ".csv or text files).\n",
        "\n",
        "As the fit progresses, results are written to the `output` folder on the fly using the highest likelihood model found\n",
        "by the non-linear search so far. This means you can inspect the results of the model-fit as it runs, without having to\n",
        "wait for the non-linear search to terminate.\n",
        "\n",
        "The `output` folder includes:\n",
        "\n",
        " - `model.info`: Summarizes the model, its parameters and their priors discussed in the next tutorial.\n",
        "\n",
        " - `model.results`: Summarizes the highest likelihood model inferred so far including errors.\n",
        "\n",
        " - `images`: Visualization of the highest likelihood model-fit to the dataset, (e.g. a fit subplot showing the \n",
        " galaxies, model data and residuals).\n",
        "\n",
        " - `files`: A folder containing .fits files of the dataset, the model as a human-readable .json file, \n",
        " a `.csv` table of every non-linear search sample and other files containing information about the model-fit.\n",
        "\n",
        " - search.summary: A file providing summary statistics on the performance of the non-linear search.\n",
        "\n",
        " - `search_internal`: Internal files of the non-linear search (in this case Nautilus) used for resuming the fit and\n",
        "  visualizing the search.\n",
        "\n",
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format.\n",
        "\n",
        "[Above, we discussed that the `info_whitespace_length` parameter in the config files could b changed to make \n",
        "the `model.info` attribute display optimally on your computer. This attribute also controls the whitespace of the\n",
        "`result.info` attribute.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Result` object also contains:\n",
        "\n",
        " - The model corresponding to the maximum log likelihood solution in parameter space.\n",
        " - The corresponding maximum log likelihood `Ellipse` and `FitEllipse` objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = result.max_log_likelihood_instance\n",
        "\n",
        "print(\"Max Log Likelihood Model:\")\n",
        "print(instance)\n",
        "\n",
        "print(f\"First Ellipse Centre: {instance.ellipses[0].centre}\")\n",
        "print(f\"First Ellipse Elliptical Components: {instance.ellipses[0].ell_comps}\")\n",
        "print(f\"First Ellipse Major Axis: {instance.ellipses[0].major_axis}\")\n",
        "print(f\"First Ellipse Axis Ratio: {instance.ellipses[0].axis_ratio}\")\n",
        "print(f\"First Ellipse Angle: {instance.ellipses[0].angle}\")\n",
        "\n",
        "for i, ellipse in enumerate(result.max_log_likelihood_instance.ellipses):\n",
        "    print(f\"Ellipse {i} Minor Axis: {ellipse.minor_axis}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The maximum log likelihood fit is also available via the result, which can visualize the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitEllipsePlotter(\n",
        "    fit_list=result.max_log_likelihood_fit_list,\n",
        "    mat_plot_2d=aplt.MatPlot2D(use_log10=True),\n",
        ")\n",
        "fit_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result contains the full posterior information of our non-linear search, including all parameter samples, \n",
        "log likelihood values and tools to compute the errors on the model. \n",
        "\n",
        "There are built in visualization tools for plotting this.\n",
        "\n",
        "The plot is labeled with short hand parameter names (e.g. `sersic_index` is mapped to the short hand \n",
        "parameter `n`). These mappings ate specified in the `config/notation.yaml` file and can be customized by users.\n",
        "\n",
        "The superscripts of labels correspond to the name each component was given in the model (e.g. for the `Isothermal`\n",
        "mass its name `mass` defined when making the `Model` above is used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_cornerpy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Multiple Ellipses__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "number_of_ellipses = 10\n",
        "\n",
        "major_axis_list = np.linspace(0.3, mask_radius * 0.9, number_of_ellipses)\n",
        "\n",
        "total_ellipses = len(major_axis_list)\n",
        "\n",
        "result_list = []\n",
        "\n",
        "for i in range(len(major_axis_list)):\n",
        "    ellipse = af.Model(ag.Ellipse)\n",
        "\n",
        "    ellipse.centre.centre_0 = result.instance.ellipses[0].centre[0]\n",
        "    ellipse.centre.centre_1 = result.instance.ellipses[0].centre[1]\n",
        "\n",
        "    ellipse.ell_comps.ell_comps_0 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "    ellipse.ell_comps.ell_comps_1 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "\n",
        "    ellipse.major_axis = major_axis_list[i]\n",
        "\n",
        "    model = af.Collection(ellipses=[ellipse])\n",
        "\n",
        "    search = af.DynestyStatic(\n",
        "        path_prefix=path.join(\"ellipse\"),\n",
        "        name=f\"fit_{i}\",\n",
        "        unique_tag=dataset_name,\n",
        "        sample=\"rwalk\",\n",
        "        n_live=50,\n",
        "        number_of_cores=4,\n",
        "        iterations_per_update=10000,\n",
        "    )\n",
        "\n",
        "    analysis = ag.AnalysisEllipse(dataset=dataset)\n",
        "\n",
        "    result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "    result_list.append(result)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Final Fit__\n",
        "\n",
        "A final fit is performed combining all ellipses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ellipses = [result.instance.ellipses[0] for result in result_list]\n",
        "\n",
        "model = af.Collection(ellipses=ellipses)\n",
        "\n",
        "model.dummy_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "\n",
        "search = af.Drawer(\n",
        "    path_prefix=path.join(\"ellipse\"),\n",
        "    name=f\"fit_all\",\n",
        "    unique_tag=dataset_name,\n",
        "    total_draws=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masking__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_extra_galaxies = ag.Mask2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"mask_extra_galaxies.fits\"),\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask + mask_extra_galaxies)\n",
        "\n",
        "\n",
        "number_of_ellipses = 10\n",
        "\n",
        "major_axis_list = np.linspace(0.3, mask_radius * 0.9, number_of_ellipses)\n",
        "\n",
        "total_ellipses = len(major_axis_list)\n",
        "\n",
        "result_list = []\n",
        "\n",
        "for i in range(len(major_axis_list)):\n",
        "    ellipse = af.Model(ag.Ellipse)\n",
        "\n",
        "    ellipse.centre.centre_0 = result.instance.ellipses[0].centre[0]\n",
        "    ellipse.centre.centre_1 = result.instance.ellipses[0].centre[1]\n",
        "\n",
        "    ellipse.ell_comps.ell_comps_0 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "    ellipse.ell_comps.ell_comps_1 = af.UniformPrior(lower_limit=-0.6, upper_limit=0.6)\n",
        "\n",
        "    ellipse.major_axis = major_axis_list[i]\n",
        "\n",
        "    model = af.Collection(ellipses=[ellipse])\n",
        "\n",
        "    search = af.DynestyStatic(\n",
        "        path_prefix=path.join(\"ellipse_mask_2\"),\n",
        "        name=f\"fit_{i}\",\n",
        "        unique_tag=dataset_name,\n",
        "        sample=\"rwalk\",\n",
        "        n_live=50,\n",
        "        number_of_cores=4,\n",
        "        iterations_per_update=10000,\n",
        "    )\n",
        "\n",
        "    analysis = ag.AnalysisEllipse(dataset=dataset)\n",
        "\n",
        "    result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "    result_list.append(result)\n",
        "\n",
        "ellipses = [result.instance.ellipses[0] for result in result_list]\n",
        "\n",
        "model = af.Collection(ellipses=ellipses)\n",
        "\n",
        "model.dummy_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "\n",
        "search = af.Drawer(\n",
        "    path_prefix=path.join(\"ellipse_mask_2\"),\n",
        "    name=f\"fit_all\",\n",
        "    unique_tag=dataset_name,\n",
        "    total_draws=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This script gives a concise overview of the ellipse fitting modeling API, fitting one the simplest models possible.\n",
        "So, what next? \n",
        "\n",
        "__Data Preparation__\n",
        "\n",
        "If you are looking to fit your own CCD imaging data of a galaxy, checkout  \n",
        "the `autogalaxy_workspace/*/data_preparation/imaging/start_here.ipynb` script for an overview of how data should be \n",
        "prepared before being modeled.\n",
        "\n",
        "__HowToGalaxy__\n",
        "\n",
        "This example script above explains ellipse fitting, but there are many other ways to model a galaxy, using\n",
        "light profiles which represent its surface brightness. \n",
        "\n",
        "This is explained in the **HowToGalaxy** Jupyter notebook lectures, found at `autogalaxy_workspace/*/howtogalaxy`. \n",
        "\n",
        "I recommend that you check them out if you are interested in more details!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}