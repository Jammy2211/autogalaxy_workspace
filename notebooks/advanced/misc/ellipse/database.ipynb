{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Database\n",
        "=================\n",
        "\n",
        "In this tutorial, we use the aggregator to load models and data from a non-linear search and use them to perform\n",
        "ellipse fits to the data.\n",
        "\n",
        "We show how to use these tools to inspect the maximum log likelihood model of a fit to the data, customize things\n",
        "like its visualization and also inspect fits randomly drawm from the PDF.\n",
        "\n",
        "__Database File__\n",
        "\n",
        "The aggregator can also load results from a `.sqlite` database file.\n",
        "\n",
        "This is beneficial when loading results for large numbers of model-fits (e.g. more than hundreds)\n",
        "because it is optimized for fast querying of results.\n",
        "\n",
        "See the package `results/database` for a full description of how to set up the database and the benefits it provides,\n",
        "especially if loading results from hard-disk is slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import os\n",
        "from os import path\n",
        "from pathlib import Path\n",
        "\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator__\n",
        "\n",
        "Aggregator use is different to other `results` examples, creating an .sqlite database file which is then used\n",
        "throughout the example, with API that mirrors the normal aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_name = \"ellipse\"\n",
        "\n",
        "if path.exists(Path(\"output\") / f\"{database_name}.sqlite\"):\n",
        "    os.remove(Path(\"output\") / f\"{database_name}.sqlite\")\n",
        "\n",
        "agg = af.Aggregator.from_database(\n",
        "    filename=f\"{database_name}.sqlite\", completed_only=False\n",
        ")\n",
        "\n",
        "agg.add_directory(directory=Path(\"output\") / database_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masks we used to fit the imaging data is accessible via the aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_gen = agg.values(\"dataset.mask\")\n",
        "print([mask for mask in mask_gen])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ellipses via Aggregator__\n",
        "\n",
        "Having performed a model-fit, we now want to interpret and visualize the results. In this example, we want to inspect\n",
        "the `Ellipse` objects that gave good fits to the data. \n",
        "\n",
        "Using the API shown in the `start_here.py` example this would require us to create a `Samples` object and manually \n",
        "compose our own `Ellipses` object. For large datasets, this would require us to use generators to ensure it is \n",
        "memory-light, which are cumbersome to write.\n",
        "\n",
        "This example therefore uses the `EllipsesAgg` object, which conveniently loads the `Ellipses` objects of every fit via \n",
        "generators for us. Explicit examples of how to do this via generators is given in the `advanced/manual_generator.py` \n",
        "tutorial.\n",
        "\n",
        "We get a ellipses generator via the `ag.agg.EllipsesAgg` object, where this `ellipses_gen` contains the maximum log\n",
        "likelihood `Galaxies `object of every model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ellipses_agg = ag.agg.EllipsesAgg(aggregator=agg)\n",
        "ellipses_gen = ellipses_agg.max_log_likelihood_gen_from()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now iterate over our ellipses generator to extract the information we desire.\n",
        "\n",
        "The `ellipses_gen` returns a list of `Ellipses` objects, as opposed to just a single `Ellipses` object. This is because\n",
        "only a single `Analysis` class was used in the model-fit, meaning there was only one imaging dataset that was\n",
        "fit. \n",
        "\n",
        "The `multi` package of the workspace illustrates model-fits which fit multiple datasets \n",
        "simultaneously, (e.g. multi-wavelength imaging)  by summing `Analysis` objects together, where the `ellipses_list` \n",
        "would contain multiple `Ellipses` objects.\n",
        "\n",
        "The parameters of ellipses in the `Ellipses` may vary across the datasets (e.g. different light profile intensities \n",
        "for different wavelengths), which would be reflected in the ellipses list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = ag.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.1)\n",
        "\n",
        "for ellipses_lists_list in ellipses_gen:\n",
        "    # Only one `Analysis` so take first and only ellipses.\n",
        "    ellipses = ellipses_lists_list[0]\n",
        "\n",
        "    for ellipse in ellipses:\n",
        "        print(ellipse.major_axis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fits via Aggregator__\n",
        "\n",
        "Having performed a model-fit, we now want to interpret and visualize the results. In this example, we inspect \n",
        "the `Imaging` objects that gave good fits to the data. \n",
        "\n",
        "Using the API shown in the `start_here.py` example this would require us to create a `Samples` object and manually \n",
        "compose our own `Imaging` object. For large datasets, this would require us to use generators to ensure it is \n",
        "memory-light, which are cumbersome to write.\n",
        "\n",
        "This example therefore uses the `ImagingAgg` object, which conveniently loads the `Imaging` objects of every fit via \n",
        "generators for us. Explicit examples of how to do this via generators is given in the `advanced/manual_generator.py` \n",
        "tutorial.\n",
        "\n",
        "We get a dataset generator via the `ag.agg.ImagingAgg` object, where this `dataset_gen` contains the maximum log\n",
        "likelihood `Imaging `object of every model-fit.\n",
        "\n",
        "The `dataset_gen` returns a list of `Imaging` objects, as opposed to just a single `Imaging` object. This is because\n",
        "only a single `Analysis` class was used in the model-fit, meaning there was only one `Imaging` dataset that was\n",
        "fit. \n",
        "\n",
        "The `multi` package of the workspace illustrates model-fits which fit multiple datasets \n",
        "simultaneously, (e.g. multi-wavelength imaging)  by summing `Analysis` objects together, where the `dataset_list` \n",
        "would contain multiple `Imaging` objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_agg = ag.agg.ImagingAgg(aggregator=agg)\n",
        "dataset_gen = dataset_agg.dataset_gen_from()\n",
        "\n",
        "for dataset_list in dataset_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    dataset = dataset_list[0]\n",
        "\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the aggregator to load a generator containing the fit of the maximum log likelihood model (and therefore \n",
        "galaxies) to each dataset.\n",
        "\n",
        "Analogous to the `dataset_gen` above returning a list with one `Imaging` object, the `fit_gen` returns a list of\n",
        "`FitEllipse` objects, because only one `Analysis` was used to perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = ag.agg.FitEllipseAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_lists_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit_list = fit_lists_list[0]\n",
        "\n",
        "    fit_plotter = aplt.FitEllipsePlotter(fit_list=fit_list)\n",
        "    fit_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualization Customization__\n",
        "\n",
        "The benefit of inspecting fits using the aggregator, rather than the files outputs to the hard-disk, is that we can \n",
        "customize the plots using the PyAutoGalaxy `mat_plot`.\n",
        "\n",
        "Below, we create a new function to apply as a generator to do this. However, we use a convenience method available \n",
        "in the aggregator package to set up the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = ag.agg.FitEllipseAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_lists_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit_list = fit_lists_list[0]\n",
        "\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        figure=aplt.Figure(figsize=(12, 12)),\n",
        "        title=aplt.Title(label=\"Custom Image\", fontsize=24),\n",
        "        yticks=aplt.YTicks(fontsize=24),\n",
        "        xticks=aplt.XTicks(fontsize=24),\n",
        "        cmap=aplt.Cmap(norm=\"log\", vmax=1.0, vmin=1.0),\n",
        "        colorbar_tickparams=aplt.ColorbarTickParams(labelsize=20),\n",
        "        units=aplt.Units(in_kpc=True),\n",
        "    )\n",
        "\n",
        "    fit_plotter = aplt.FitEllipsePlotter(fit_list=fit_list, mat_plot_2d=mat_plot)\n",
        "    fit_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making this plot for a paper? You can output it to hard disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = ag.agg.FitEllipseAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_lists_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit_list = fit_lists_list[0]\n",
        "\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        title=aplt.Title(label=\"Hey\"),\n",
        "        output=aplt.Output(\n",
        "            path=Path(\"output\") / \"path\" / \"of\" / \"file\",\n",
        "            filename=\"publication\",\n",
        "            format=\"png\",\n",
        "        ),\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (Random draws from PDF)__\n",
        "\n",
        "In the `examples/models.py` example we showed how `Galaxies` objects could be randomly drawn form the Probability \n",
        "Distribution Function, in order to quantity things such as errors.\n",
        "\n",
        "The same approach can be used with `FitEllipse` objects, to investigate how the properties of the fit vary within\n",
        "the errors (e.g. showing how the model galaxy appearances changes for different fits)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = ag.agg.FitEllipseAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.randomly_drawn_via_pdf_gen_from(total_samples=2)\n",
        "\n",
        "\n",
        "for fit_list_gen in fit_gen:  # Total samples 2 so fit_list_gen contains 2 fits.\n",
        "    for fit_lists_list in fit_gen:  # Iterate over each fit of total_samples=2\n",
        "        # Only one `Analysis` so take first and only dataset.\n",
        "        fit_list = fit_lists_list[0]\n",
        "\n",
        "        fit_plotter = aplt.FitEllipsePlotter(fit_list=fit_list)\n",
        "        fit_plotter.figures_2d(data=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Multipoles__\n",
        "\n",
        "If you have performed a model-fit using multipoles, the database fully supports loading these results and has\n",
        "dedicated tools for this.\n",
        "\n",
        "First, lets build a database of a model-fit using multipoles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_name = \"ellipse_multipole\"\n",
        "\n",
        "if path.exists(Path(\"output\") / f\"{database_name}.sqlite\"):\n",
        "    os.remove(Path(\"output\") / f\"{database_name}.sqlite\")\n",
        "\n",
        "agg = af.Aggregator.from_database(\n",
        "    filename=f\"{database_name}.sqlite\", completed_only=False\n",
        ")\n",
        "\n",
        "agg.add_directory(directory=Path(\"output\") / database_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Multipoles via Aggregator__\n",
        "\n",
        "Multipoles are included in the model as a separate component to the ellipses and therefore use their own separate\n",
        "aggregator object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "multipoles_agg = ag.agg.MultipolesAgg(aggregator=agg)\n",
        "multipoles_gen = multipoles_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for multipoles_lists_list in multipoles_gen:\n",
        "    # Only one `Analysis` so take first and only multipoles.\n",
        "    multipoles = multipoles_lists_list[0]\n",
        "\n",
        "    for multipole_list in multipoles:\n",
        "        print(multipole_list[0].m)\n",
        "        print(multipole_list[1].m)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `FitEllipseAgg` automatically accounts for the multipoles in the model-fit if they are present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = ag.agg.FitEllipseAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_lists_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit_list = fit_lists_list[0]\n",
        "\n",
        "    print(fit_list)\n",
        "\n",
        "    print(fit_list[0].multipole_list)\n",
        "\n",
        "    fit_plotter = aplt.FitEllipsePlotter(fit_list=fit_list)\n",
        "    fit_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}