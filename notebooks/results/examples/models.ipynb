{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Models\n",
        "===============\n",
        "\n",
        "Suppose we have the results of many fits and we only wanted to load and inspect a specific set\n",
        "of model-fits (e.g. the results of `start_here.py`). We can use querying tools to only load the results we are\n",
        "interested in.\n",
        "\n",
        "This includes support for advanced querying, so that specific model-fits (e.g., which fit a certain model or dataset)\n",
        "can be loaded.\n",
        "\n",
        "__Database File__\n",
        "\n",
        "The aggregator can also load results from a `.sqlite` database file.\n",
        "\n",
        "This is benefitial when loading results for large numbers of model-fits (e.g. more than hundreds)\n",
        "because it is optimized for fast querying of results.\n",
        "\n",
        "See the package `results/database` for a full description of how to set up the database and the benefits it provides,\n",
        "especially if loading results from hard-disk is slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator__\n",
        "\n",
        "The functionality illustrated in this example only supports results loaded via the .sqlite database.\n",
        "\n",
        "We therefore do not load results from hard-disk like other scripts, but build a .sqlite database in order\n",
        "to create the `Aggregator` object.\n",
        "\n",
        "If you have not used the .sqlite database before, the `start_here.ipynb` example describes how to set it up and the API\n",
        "for the aggregator is identical from here on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_name = \"results_folder\"\n",
        "\n",
        "if path.exists(path.join(\"output\", f\"{database_name}.sqlite\")):\n",
        "    os.remove(path.join(\"output\", f\"{database_name}.sqlite\"))\n",
        "\n",
        "agg = af.Aggregator.from_database(\n",
        "    filename=f\"{database_name}.sqlite\", completed_only=False\n",
        ")\n",
        "\n",
        "agg.add_directory(directory=path.join(\"output\", database_name))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxies via Aggregator__\n",
        "\n",
        "Having performed a model-fit, we now want to interpret and visualize the results. In this example, we want to inspect\n",
        "the `Galaxies` objects that gave good fits to the data. \n",
        "\n",
        "Using the API shown in the `start_here.py` example this would require us to create a `Samples` object and manually \n",
        "compose our own `Galaxies` object. For large datasets, this would require us to use generators to ensure it is memory-light,\n",
        "which are cumbersome to write.\n",
        "\n",
        "This example therefore uses the `GalaxiesAgg` object, which conveniently loads the `Galaxies` objects of every fit via \n",
        "generators for us. Explicit examples of how to do this via generators is given in the `advanced/manual_generator.py` \n",
        "tutorial.\n",
        "\n",
        "We get a galaxies generator via the `ag.agg.GalaxiesAgg` object, where this `galaxies_gen` contains the maximum log\n",
        "likelihood `Plane `object of every model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies_agg = ag.agg.GalaxiesAgg(aggregator=agg)\n",
        "galaxies_gen = galaxies_agg.max_log_likelihood_gen_from()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now iterate over our galaxies generator to make the plots we desire.\n",
        "\n",
        "The `galaxies_gen` returns a list of `Galaxies` objects, as opposed to just a single `Galaxies` object. This is because\n",
        "only a single `Analysis` class was used in the model-fit, meaning there was only one imaging dataset that was\n",
        "fit. \n",
        "\n",
        "The `multi` package of the workspace illustrates model-fits which fit multiple datasets \n",
        "simultaneously, (e.g. multi-wavelength imaging)  by summing `Analysis` objects together, where the `galaxies_list` \n",
        "would contain multiple `Galaxies` objects.\n",
        "\n",
        "The parameters of galaxies in the `Galaxies` may vary across the datasets (e.g. different light profile intensities \n",
        "for different wavelengths), which would be reflected in the galaxies list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = ag.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.1)\n",
        "\n",
        "for galaxies_list in galaxies_gen:\n",
        "    # Only one `Analysis` so take first and only galaxies.\n",
        "    galaxies = galaxies_list[0]\n",
        "\n",
        "    galaxies_plotter = aplt.GalaxiesPlotter(galaxies=galaxies, grid=grid)\n",
        "    galaxies_plotter.figures_2d(convergence=True, potential=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Luminosity Example__\n",
        "\n",
        "Each galaxies has the information we need to compute the luminosity of that model. Therefore, lets print \n",
        "the luminosity of each of our most-likely galaxies.\n",
        "\n",
        "The model instance uses the model defined by a pipeline. In this pipeline, we called the galaxy `galaxy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies_agg = ag.agg.GalaxiesAgg(aggregator=agg)\n",
        "galaxies_gen = galaxies_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "print(\"Maximum Log Likelihood Luminosities:\")\n",
        "\n",
        "for galaxies_list in galaxies_gen:\n",
        "    # Only one `Analysis` so take first and only tracer.\n",
        "    galaxies = galaxies_list[0]\n",
        "\n",
        "    luminosity = galaxies[0].luminosity_within_circle_from(radius=10.0)\n",
        "\n",
        "    print(\"Luminosity (electrons per second) = \", luminosity)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (PDF from samples)__\n",
        "\n",
        "In this example, we will compute the errors on the axis ratio of a model. Computing the errors on a quantity \n",
        "like the trap `density` is simple, because it is sampled by the non-linear search. The errors are therefore accessible\n",
        "via the `Samples`, by marginalizing over all over parameters via the 1D Probability Density Function (PDF).\n",
        "\n",
        "Computing the errors on the axis ratio is more tricky, because it is a derived quantity. It is a parameter or \n",
        "measurement that we want to calculate but was not sampled directly by the non-linear search. The `GalaxiesAgg` object \n",
        "object has everything we need to compute the errors of derived quantities.\n",
        "\n",
        "Below, we compute the axis ratio of every model sampled by the non-linear search and use this determine the PDF \n",
        "of the axis ratio. When combining each axis ratio we weight each value by its `weight`. For Nautilus, \n",
        "the nested sampler used by the fit, this ensures models which gave a bad fit (and thus have a low weight) do not \n",
        "contribute significantly to the axis ratio error estimate.\n",
        "\n",
        "We set `minimum_weight=`1e-4`, such that any sample with a weight below this value is discarded when computing the \n",
        "error. This speeds up the error computation by only using a small fraction of the total number of samples. Computing\n",
        "a axis ratio is cheap, and this is probably not necessary. However, certain quantities have a non-negligible\n",
        "computational overhead is being calculated and setting a minimum weight can speed up the calculation without \n",
        "significantly changing the inferred errors.\n",
        "\n",
        "Below, we use the `GalaxiesAgg` to get the `Plane` of every Nautilus sample in each model-fit. We extract from each \n",
        "galaxies the model's axis-ratio, store them in a list and find the value via the PDF and quantile method. This again\n",
        "uses generators, ensuring minimal memory use. \n",
        "\n",
        "In order to use these samples in the function `quantile`, we also need the weight list of the sample weights. We \n",
        "compute this using the `GalaxiesAgg`'s function `weights_above_gen_from`, which computes generators of the weights of all \n",
        "points above this minimum value. This again ensures memory use in minimag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies_agg = ag.agg.GalaxiesAgg(aggregator=agg)\n",
        "galaxies_list_gen = galaxies_agg.all_above_weight_gen_from(minimum_weight=1e-4)\n",
        "weight_list_gen = galaxies_agg.weights_above_gen_from(minimum_weight=1e-4)\n",
        "\n",
        "for galaxies_gen, weight_gen in zip(galaxies_list_gen, weight_list_gen):\n",
        "    axis_ratio_list = []\n",
        "\n",
        "    for galaxies_list in galaxies_gen:\n",
        "        # Only one `Analysis` so take first and only tracer.\n",
        "        galaxies = galaxies_list[0]\n",
        "\n",
        "        axis_ratio = ag.convert.axis_ratio_from(ell_comps=galaxies[0].bulge.ell_comps)\n",
        "\n",
        "        axis_ratio_list.append(axis_ratio)\n",
        "\n",
        "    weight_list = [weight for weight in weight_gen]\n",
        "\n",
        "    try:\n",
        "        median_axis_ratio, lower_axis_ratio, upper_axis_ratio = af.marginalize(\n",
        "            parameter_list=axis_ratio_list, sigma=3.0, weight_list=weight_list\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"Axis-Ratio = {median_axis_ratio} ({upper_axis_ratio} {lower_axis_ratio}\"\n",
        "        )\n",
        "    except IndexError:\n",
        "        pass"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (Random draws from PDF)__\n",
        "\n",
        "An alternative approach to estimating the errors on a derived quantity is to randomly draw samples from the PDF \n",
        "of the non-linear search. For a sufficiently high number of random draws, this should be as accurate and precise\n",
        "as the method above. However, it can be difficult to be certain how many random draws are necessary.\n",
        "\n",
        "The weights of each sample are used to make every random draw. Therefore, when we compute the axis-ratio and its errors\n",
        "we no longer need to pass the `weight_list` to the `quantile` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies_agg = ag.agg.GalaxiesAgg(aggregator=agg)\n",
        "galaxies_list_gen = galaxies_agg.randomly_drawn_via_pdf_gen_from(total_samples=2)\n",
        "\n",
        "for galaxies_gen in galaxies_list_gen:\n",
        "    axis_ratio_list = []\n",
        "\n",
        "    for galaxies_list in galaxies_gen:\n",
        "        # Only one `Analysis` so take first and only tracer.\n",
        "        galaxies = galaxies_list[0]\n",
        "\n",
        "        axis_ratio = ag.convert.axis_ratio_from(ell_comps=galaxies[0].bulge.ell_comps)\n",
        "\n",
        "        axis_ratio_list.append(axis_ratio)\n",
        "\n",
        "    median_axis_ratio, lower_axis_ratio, upper_axis_ratio = af.marginalize(\n",
        "        parameter_list=axis_ratio_list, sigma=3.0\n",
        "    )\n",
        "\n",
        "    print(f\"Axis-Ratio = {median_axis_ratio} ({upper_axis_ratio} {lower_axis_ratio}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}