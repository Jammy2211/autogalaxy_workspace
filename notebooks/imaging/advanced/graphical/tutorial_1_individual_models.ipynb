{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 1:  Individual Models\n",
        "==============================\n",
        "\n",
        "The example scripts throughout the workspace have focused on fitting a galaxy model to one dataset. You will have\n",
        "inspected the results of those individual model-fits and used them to estimate properties of the galaxy, like its\n",
        "brightness and size.\n",
        "\n",
        "You may even have analysed a sample consisting of tens of objects, and combined the results to make more general\n",
        "statements about galaxy formation or cosmology. That is, deduce  'global' trends of many models fits a galaxy sample.\n",
        "\n",
        "These tutorials show you how to compose and fit graphical models to a large datasets. A graphical model fits many\n",
        "individual models to each dataset in your sample, but it also links parameters in these models together to\n",
        "enable global inference on the model over the full dataset.\n",
        "\n",
        "To illustrate this, these tutorials will use graphical models to infer the Sersic index across a sample of galaxies.\n",
        "Graphical models will be used to determine the global distribution from which the Sersic index are drawn, which uses\n",
        "specific type of graphical model called a hierarchical model.\n",
        "\n",
        "The first two tutorials will begin by simplifying the problem. We are going to fit a sample of 3 galaxies whose light\n",
        "profiles are `Sersic` profiles which all have the same `sersic_index` value. We can therefore consider\n",
        "the `sersic_index`  the global parameter we seek to estimate.\n",
        "\n",
        "The data that we fit is going to be low resolution, meaning that our estimate of each `sersic_index` has large errors.\n",
        "To estimate the global Sersic index of the sample, this tutorial does not use graphical models, but instead estimates\n",
        "the `sersic_index` by fitting each dataset one-by-one and combining the results post model-fitting. This will act as a \n",
        "point of comparison to tutorial 2, where we will fit for the sersic_index using graphical models.\n",
        "\n",
        "__Sample Simulation__\n",
        "\n",
        "The dataset fitted in this example script is simulated imaging data of a sample of 3 galaxies.\n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the\n",
        "script `autogalaxy_workspace/scripts/simulators/imaging/samples/dev.py`.\n",
        "\n",
        "__PyAutoFit Tutorials__\n",
        "\n",
        "**PyAutoFit** has dedicated tutorials describing graphical models, which users not familiar with graphical\n",
        "modeling may benefit from reading -- https://pyautofit.readthedocs.io/en/latest/howtofit/chapter_graphical_models.html.\n",
        "\n",
        "__Realism__\n",
        "\n",
        "For an realistic galaxy sample, one would not expect that each galaxy has the same value of `sersic_index`, as is\n",
        "assumed in tutorials 1, 2 and 3. We make this assumption here to simplify the problem and make it easier to\n",
        "illustrate graphical models. Later tutorials fit more realistic graphical models where each galaxy has its own value of\n",
        "Sersic index!\n",
        "\n",
        "One can easily imagine datasets where the shared parameter is the same across the full sample. For example, studies\n",
        "where cosmological parameters (e.g. the Hubble constant, H0) are included in the graphical mode. The tools introduced\n",
        "in tutorials 1 and 2 could therefore be used for many science cases!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "For each dataset in our sample we set up the correct path and load it by iterating over a for loop. \n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the \n",
        "script `autogalaxy_workspace/scripts/simulators/imaging/samples/dev.py`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"imaging\"\n",
        "dataset_sample_name = \"dev\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_sample_name)\n",
        "\n",
        "total_datasets = 3\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = path.join(dataset_path, f\"dataset_{dataset_index}\")\n",
        "\n",
        "    dataset_list.append(\n",
        "        ag.Imaging.from_fits(\n",
        "            data_path=path.join(dataset_sample_path, \"data.fits\"),\n",
        "            psf_path=path.join(dataset_sample_path, \"psf.fits\"),\n",
        "            noise_map_path=path.join(dataset_sample_path, \"noise_map.fits\"),\n",
        "            pixel_scales=0.1,\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We now mask each galaxy in our dataset, using the imaging list we created above.\n",
        "\n",
        "We will assume a 3.0\" mask for every galaxy in the dataset is appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    mask = ag.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "\n",
        "    masked_imaging_list.append(dataset.apply_mask(mask=mask))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "The path the results of all model-fits are output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = path.join(\"imaging\", \"graphical\", \"tutorial_1_individual_models\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data. In this \n",
        "example we fit a model where:\n",
        "\n",
        " - The galaxy's bulge is a parametric `Sersic` bulge with its centre fixed to the input \n",
        " value of (0.0, 0.0) [5 parameters]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(ag.lp.Sersic)\n",
        "bulge.centre = (0.0, 0.0)\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Analysis + Model-Fit__\n",
        "\n",
        "For each dataset we now create a non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "Results are output to a unique folder named using the `dataset_index`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_list = []\n",
        "\n",
        "for dataset_index, masked_dataset in enumerate(masked_imaging_list):\n",
        "    dataset_name_with_index = f\"dataset_{dataset_index}\"\n",
        "    path_prefix_with_index = path.join(path_prefix, dataset_name_with_index)\n",
        "\n",
        "    search = af.DynestyStatic(\n",
        "        path_prefix=path_prefix,\n",
        "        name=\"search__light_sersic\",\n",
        "        unique_tag=dataset_name_with_index,\n",
        "        nlive=50,\n",
        "    )\n",
        "\n",
        "    analysis = ag.AnalysisImaging(dataset=masked_dataset)\n",
        "\n",
        "    result = search.fit(model=model, analysis=analysis)\n",
        "    result_list.append(result)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Results__\n",
        "\n",
        "In the `model.results` file of each fit, it will be clear that the `sersic_index` value of every fit (and the other \n",
        "parameters) have much larger errors than other **PyAutoGalaxy** examples due to the low signal to noise of the data.\n",
        "\n",
        "The `result_list` allows us to plot the median PDF value and 3.0 confidence intervals of the `sersic_index` estimate \n",
        "from the model-fit to each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples_list = [result.samples for result in result_list]\n",
        "\n",
        "mp_instances = [samps.median_pdf() for samps in samples_list]\n",
        "ue3_instances = [samp.errors_at_upper_sigma(sigma=3.0) for samp in samples_list]\n",
        "le3_instances = [samp.errors_at_lower_sigma(sigma=3.0) for samp in samples_list]\n",
        "\n",
        "mp_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in mp_instances\n",
        "]\n",
        "ue3_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in ue3_instances\n",
        "]\n",
        "le3_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in le3_instances\n",
        "]\n",
        "\n",
        "print(mp_sersic_indexes)\n",
        "\n",
        "plt.errorbar(\n",
        "    x=[\"galaxy 1\", \"galaxy 2\", \"galaxy 3\"],\n",
        "    y=mp_sersic_indexes,\n",
        "    marker=\".\",\n",
        "    linestyle=\"\",\n",
        "    yerr=[le3_sersic_indexes, ue3_sersic_indexes],\n",
        ")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These model-fits are consistent with the input  `sersic_index` values of 4.0. \n",
        "\n",
        "We can show this by plotting the 1D and 2D PDF's of each model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "for samples in samples_list:\n",
        "    search_plotter = aplt.DynestyPlotter(samples=samples)\n",
        "    search_plotter.cornerplot()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the values of each Sersic index estimate, including their estimates at 3.0 sigma.\n",
        "\n",
        "Note that above we used the samples to estimate the size of the errors on the parameters. Below, we use the samples to \n",
        "get the value of the parameter at these sigma confidence intervals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "u1_instances = [samp.values_at_upper_sigma(sigma=1.0) for samp in samples_list]\n",
        "l1_instances = [samp.values_at_lower_sigma(sigma=1.0) for samp in samples_list]\n",
        "\n",
        "u1_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in u1_instances\n",
        "]\n",
        "l1_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in l1_instances\n",
        "]\n",
        "\n",
        "u3_instances = [samp.values_at_upper_sigma(sigma=3.0) for samp in samples_list]\n",
        "l3_instances = [samp.values_at_lower_sigma(sigma=3.0) for samp in samples_list]\n",
        "\n",
        "u3_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in u3_instances\n",
        "]\n",
        "l3_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in l3_instances\n",
        "]\n",
        "\n",
        "for index in range(total_datasets):\n",
        "    print(f\"Sersic Index estimate of galaxy dataset {index}:\\n\")\n",
        "    print(\n",
        "        f\"{mp_sersic_indexes[index]} ({l1_sersic_indexes[index]} {u1_sersic_indexes[index]}) [1.0 sigma confidence interval]\"\n",
        "    )\n",
        "    print(\n",
        "        f\"{mp_sersic_indexes[index]} ({l3_sersic_indexes[index]} {u3_sersic_indexes[index]}) [3.0 sigma confidence interval] \\n\"\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Estimating the Sersic Index__\n",
        "\n",
        "So how might we estimate the global `sersic_index`, that is the value of Sersic index we know all 3 galaxies were \n",
        "simulated using? \n",
        "\n",
        "A simple approach takes the weighted average of the value inferred by all fits above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ue1_instances = [samp.values_at_upper_sigma(sigma=1.0) for samp in samples_list]\n",
        "le1_instances = [samp.values_at_lower_sigma(sigma=1.0) for samp in samples_list]\n",
        "\n",
        "ue1_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in ue1_instances\n",
        "]\n",
        "le1_sersic_indexes = [\n",
        "    instance.galaxies.galaxy.bulge.sersic_index for instance in le1_instances\n",
        "]\n",
        "\n",
        "error_list = [ue1 - le1 for ue1, le1 in zip(ue1_sersic_indexes, le1_sersic_indexes)]\n",
        "\n",
        "values = np.asarray(mp_sersic_indexes)\n",
        "sigmas = np.asarray(error_list)\n",
        "\n",
        "weights = 1 / sigmas**2.0\n",
        "weight_averaged = np.sum(1.0 / sigmas**2)\n",
        "\n",
        "weighted_sersic_index = np.sum(values * weights) / np.sum(weights, axis=0)\n",
        "weighted_error = 1.0 / np.sqrt(weight_averaged)\n",
        "\n",
        "print(\n",
        "    f\"Weighted Average Sersic Index Estimate = {weighted_sersic_index} ({weighted_error}) [1.0 sigma confidence intervals]\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Posterior Multiplication__\n",
        "\n",
        "An alternative and more accurate way to combine each individual inferred Sersic index is multiply their posteriors \n",
        "together.\n",
        "\n",
        "In order to do this, a smooth 1D profile must be fit to the posteriors via a Kernel Density Estimator (KDE).\n",
        "\n",
        "[**PyAutoGalaxy** does not currently support posterior multiplication and an example illustrating this is currently\n",
        "missing from this tutorial. However, I will discuss KDE multiplication throughout these tutorials to give the\n",
        "reader context for how this approach to parameter estimation compares to graphical models.]\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Lets wrap up the tutorial. The methods used above combine the results of different fits and estimate a global \n",
        "value of `sersic_index` alongside estimates of its error. \n",
        "\n",
        "In this tutorial, we fitted just 5 datasets. Of course, we could easily fit more datasets, and we would find that\n",
        "as we added more datasets our estimate of the global Sersic index would become more precise.\n",
        "\n",
        "In the next tutorial, we will compare this result to one inferred via a graphical model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}