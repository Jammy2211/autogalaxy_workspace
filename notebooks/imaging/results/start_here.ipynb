{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Start Here\n",
        "===================\n",
        "\n",
        "This script is the starting point for investigating the results of modeling and it provides\n",
        "an overview of the modeling API.\n",
        "\n",
        "After reading this script, the `examples` folder provides more detailed examples for analysing the different aspects of\n",
        "performing modeling results outlined here.\n",
        "\n",
        "__Model__\n",
        "\n",
        "We begin by fitting a quick model to a simple dataset, which we will use to illustrate the modeling\n",
        "results API.\n",
        "\n",
        "If you are not familiar with the modeling API and process, checkout the `autogalaxy_workspace/examples/modeling`\n",
        "folder for examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below performs a model-fit using nautilus. \n",
        "\n",
        "You should be familiar with modeling already, if not read the `modeling/start_here.py` script before reading this one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "bulge = af.Model(ag.lp.Sersic)\n",
        "disk = af.Model(ag.lp.Exponential)\n",
        "bulge.centre = disk.centre\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"light[bulge_disk]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = ag.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Info__\n",
        "\n",
        "As seen throughout the workspace, the `info` attribute shows the result in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading From Hard-disk__\n",
        "\n",
        "When performing fits which output results to hard-disk, a `files` folder is created containing .json / .csv files of \n",
        "the model, samples, search, etc. You should check it out now for a completed fit on your hard-disk if you have\n",
        "not already!\n",
        "\n",
        "These files can be loaded from hard-disk to Python variables via the aggregator, making them accessible in a \n",
        "Python script or Jupyter notebook. They are loaded as the internal **PyAutoFit** objects we are familiar with,\n",
        "for example the `model` is loaded as the `Model` object we passed to the search above.\n",
        "\n",
        "Below, we will access these results using the aggregator's `values` method. A full list of what can be loaded is\n",
        "as follows:\n",
        "\n",
        " - `model`: The `model` defined above and used in the model-fit (`model.json`).\n",
        " - `search`: The non-linear search settings (`search.json`).\n",
        " - `samples`: The non-linear search samples (`samples.csv`).\n",
        " - `samples_info`: Additional information about the samples (`samples_info.json`).\n",
        " - `samples_summary`: A summary of key results of the samples (`samples_summary.json`).\n",
        " - `info`: The info dictionary passed to the search (`info.json`).\n",
        " - `covariance`: The inferred covariance matrix (`covariance.csv`).\n",
        " - `data`: The 1D noisy data used that is fitted (`data.json`).\n",
        " - `noise_map`: The 1D noise-map fitted (`noise_map.json`).\n",
        "\n",
        "The `samples` and `samples_summary` results contain a lot of repeated information. The `samples` result contains\n",
        "the full non-linear search samples, for example every parameter sample and its log likelihood. The `samples_summary`\n",
        "contains a summary of the results, for example the maximum log likelihood model and error estimates on parameters\n",
        "at 1 and 3 sigma confidence.\n",
        "\n",
        "Accessing results via the `samples_summary` is much faster, because as it does not reperform calculations using the full \n",
        "list of samples. Therefore, if the result you want is accessible via the `samples_summary` you should use it\n",
        "but if not you can revert to the `samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autofit.aggregator.aggregator import Aggregator\n",
        "\n",
        "agg = Aggregator.from_directory(\n",
        "    directory=path.join(\"output\", \"cookbook_result\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Generators__\n",
        "\n",
        "Before using the aggregator to inspect results, lets discuss Python generators. \n",
        "\n",
        "A generator is an object that iterates over a function when it is called. The aggregator creates all of the objects \n",
        "that it loads from the database as generators (as opposed to a list, or dictionary, or another Python type).\n",
        "\n",
        "This is because generators are memory efficient, as they do not store the entries of the database in memory \n",
        "simultaneously. This contrasts objects like lists and dictionaries, which store all entries in memory all at once. \n",
        "If you fit a large number of datasets, lists and dictionaries will use a lot of memory and could crash your computer!\n",
        "\n",
        "Once we use a generator in the Python code, it cannot be used again. To perform the same task twice, the \n",
        "generator must be remade it. This cookbook therefore rarely stores generators as variables and instead uses the \n",
        "aggregator to create each generator at the point of use.\n",
        "\n",
        "To create a generator of a specific set of results, we use the `values` method. This takes the `name` of the\n",
        "object we want to create a generator of, for example inputting `name=samples` will return the results `Samples`\n",
        "object (which is illustrated in detail below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples__\n",
        "\n",
        "The result's `Samples` object contains the complete set of non-linear search nautilus samples, where each sample \n",
        "corresponds to a set of model parameters that were evaluated and accepted. \n",
        "\n",
        "The examples script `autogalaxy_workspace/*/imaging/results/examples/samples.py` provides a detailed description of \n",
        "this object, including:\n",
        "\n",
        " - Extracting the maximum likelihood model.\n",
        " - Using marginalized PDFs to estimate errors on the model parameters.\n",
        " - Deriving errors on derived quantities, such as the Einstein radius.\n",
        "\n",
        "Below, is an example of how to use the `Samples` object to estimate the mass model parameters which are \n",
        "the median of the probability distribution function and its errors at 3 sigma confidence intervals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "median_pdf_instance = samples.median_pdf()\n",
        "\n",
        "print(\"Median PDF Model Instances: \\n\")\n",
        "print(median_pdf_instance.galaxies.galaxy.bulge)\n",
        "print()\n",
        "\n",
        "ue3_instance = samples.values_at_upper_sigma(sigma=3.0)\n",
        "le3_instance = samples.values_at_lower_sigma(sigma=3.0)\n",
        "\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(ue3_instance.galaxies.galaxy.bulge, \"\\n\")\n",
        "print(le3_instance.galaxies.galaxy.bulge, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxies__\n",
        "\n",
        "The result's maximum likelihood `Plane` object contains everything necessary to perform calculations with the model\n",
        "like retrieving the images of each galaxy.\n",
        "\n",
        "The examples script `autogalaxy_workspace/*/imaging/results/examples/galaxies.py` provides a detailed \n",
        "description of this object, including:\n",
        "\n",
        " - Producing individual images of the galaxies.\n",
        " - Inspecting mass model components like the convergence, potential and deflection angles.\n",
        " - Other lensing quantities like the critical curve and caustics.\n",
        "\n",
        "Below, is an example of how to use the `Plane` object to calculate the image of the galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies = result.max_log_likelihood_galaxies\n",
        "\n",
        "image = galaxies.image_2d_from(grid=dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fits__\n",
        "\n",
        "The result's maximum likelihood `FitImaging` object contains everything necessary to inspect the model fit to the \n",
        "data.\n",
        "\n",
        "The examples script `autogalaxy_workspace/*/imaging/results/examples/fits.py` provides a detailed description of this \n",
        "object, including:\n",
        "\n",
        " - How to inspect the residuals, chi-squared, likelihood and other quantities.\n",
        " - Outputting resulting images (e.g. the galaxy reconstruction) to hard-disk.\n",
        " - Refitting the data with other models from the `Samples` object, to investigate how sensitive the fit is to\n",
        "   different models.\n",
        "\n",
        "Below, is an example of how to use the `FitImaging` object to output the galaxy reconstruction to print the \n",
        "chi-squared and log likelihood values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = result.max_log_likelihood_fit\n",
        "\n",
        "print(fit.chi_squared)\n",
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxies__\n",
        "\n",
        "The result's maximum likelihood `Galaxy` objects contain everything necessary to inspect the individual properties of\n",
        "the galaxies.\n",
        "\n",
        "The examples script `autogalaxy_workspace/*/imaging/results/examples/galaxies.py` provides a detailed description \n",
        "of this object, including:\n",
        "\n",
        " - How to plot individual galaxy images, such as the galaxy's images.\n",
        " - Plotting the individual light profiles and mass profiles of the galaxies.\n",
        " - Making one dimensional profiles of the galaxies, such as their light and mass profiles as a function of radius.\n",
        " \n",
        "Below, is an example of how to use the `Galaxy` objects to plot the galaxy's image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies = result.max_log_likelihood_galaxies\n",
        "\n",
        "galaxy = galaxies[0]\n",
        "galaxy_plotter = aplt.GalaxyPlotter(galaxy=galaxy, grid=dataset.grid)\n",
        "galaxy_plotter.figures_2d(image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Cosmological Quantities__\n",
        "\n",
        "The maximum likelihood model includes cosmological quantities, which can be computed via the result.\n",
        "\n",
        "The examples script `autogalaxy_workspace/*/imaging/results/examples/cosmological_quantities.py` provides a detailed \n",
        "description of this object, including:\n",
        "\n",
        " - Calculating the Einstein radius of the galaxy.\n",
        " - Converting quantities like the Einstein radius or effective radius from arcseconds to kiloparsecs.\n",
        " - Computing the Einstein mass of the galaxy in solar masses.\n",
        " \n",
        "Below, is an example of how to convert the effective radius of the galaxy from arcseconds to kiloparsecs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies = result.max_log_likelihood_galaxies\n",
        "\n",
        "cosmology = ag.cosmo.Planck15()\n",
        "\n",
        "galaxy = galaxies[0]\n",
        "galaxy_kpc_per_arcsec = cosmology.kpc_per_arcsec_from(redshift=galaxy.redshift)\n",
        "galaxy_effective_radius_kpc = galaxy.bulge.effective_radius * galaxy_kpc_per_arcsec"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Light Profiles / Basis Objects__\n",
        "\n",
        "A model can be fitted using a linear light profile, which is a light profile whose `intensity` parameter is \n",
        "sovled for via linear algebra.\n",
        "\n",
        "This includes Basis objects such as a Multi-Gaussian expansion of Shapelets.\n",
        "\n",
        "These objects mostly behave identically to ordinary light profiles, but due to the linear algebra have their own\n",
        "specific functionality.\n",
        "\n",
        "The example script `autogalaxy_workspace/*/imaging/results/examples/linear.py` provides a detailed description of \n",
        "this functionality, including:\n",
        "\n",
        " - Extracting individual quantities from the linear light profile, such as the coefficients of the basis functions.\n",
        " - Extracting the intensity of the linear light profiles after they have been computed via linear algebra.\n",
        " - Plotting the linear light profiles.\n",
        " \n",
        "The fit above did not use a pixelization, so we omit a example of the API below.\n",
        "\n",
        "__Pixelization__\n",
        "\n",
        "The model can reconstruct the galaxy using a pixelization, for example on a Voronoi mesh.\n",
        "\n",
        "The example script `autogalaxy_workspace/*/imaging/results/examples/pixelizations.py` provides a detailed description \n",
        "of inspecting the results of a fit using a pixelization, including:\n",
        "\n",
        " - Producing galaxy reconstructions using the Voronoi mesh, Delaunay triangulation or whichever mesh is used.\n",
        " - Inspecting the evidence terms of the fit, which quantify how well the pixelization reconstructs fits the data whilst\n",
        "   accounting for the complexity of the pixelization.\n",
        " - Estimating the magnification of the galaxy's image using the pixelization.\n",
        "\n",
        "The fit above did not use a pixelization, so we omit a example of the API below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}