{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Searches: PySwarms\n",
        "==================\n",
        "\n",
        "PySwarms is a  particle swarm optimization (PSO) algorithm.\n",
        "\n",
        "Information about PySwarms can be found at the following links:\n",
        "\n",
        " - https://github.com/ljvmiranda921/pyswarms\n",
        " - https://pyswarms.readthedocs.io/en/latest/index.html\n",
        " - https://pyswarms.readthedocs.io/en/latest/api/pyswarms.single.html#module-pyswarms.single.global_best\n",
        "\n",
        "An PSO algorithm only seeks to only find the maximum likelihood model, unlike MCMC or nested sampling algorithms\n",
        "like Zzeus and nautilus, which aims to map-out parameter space and infer errors on the parameters.Therefore, in \n",
        "principle, a PSO like PySwarm should fit a model very fast.\n",
        "\n",
        "In our experience, the parameter spaces fitted by models are too complex for `PySwarms` to be used without a lot\n",
        "of user attention and care.  Nevertheless, we encourage you to give it a go yourself, and let us know on the PyAutoGalaxy \n",
        "GitHub if you find an example of a problem where `PySwarms` outperforms Nautilus!\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import numpy as np\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking__\n",
        "\n",
        "Load and plot the galaxy dataset `simple__sersic` via .fits files, which we will fit with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__ \n",
        "\n",
        "In our experience, zeus is okay at initializing a model but not as good at `nautilus. It therefore benefits \n",
        "from a 'starting point' which is near the highest likelihood models. We set this starting point up below using\n",
        "the start point API (see `autogalaxy_workspace/*/imaging/modeling/customize/start_point.ipynb`).\n",
        "\n",
        "Given this need for a robust starting point, PySwarms is only suited to model-fits where we have this information. It may\n",
        "therefore be useful when performing modeling search chaining (see HowToGalaxy chapter 3). However, even in such\n",
        "circumstances, we have found that is often unrealible and often infers a local maxima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(ag.lp_linear.Sersic)\n",
        "\n",
        "bulge.centre_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "bulge.centre_1 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "bulge.ell_comps.ell_comps_0 = af.GaussianPrior(\n",
        "    mean=0.11, sigma=0.2, lower_limit=-1.0, upper_limit=1.0\n",
        ")\n",
        "bulge.ell_comps.ell_comps_1 = af.GaussianPrior(\n",
        "    mean=0.05, sigma=0.2, lower_limit=-1.0, upper_limit=1.0\n",
        ")\n",
        "bulge.intensity = af.LogUniformPrior(lower_limit=0.5, upper_limit=1.5)\n",
        "bulge.effective_radius = af.UniformPrior(lower_limit=0.5, upper_limit=1.5)\n",
        "bulge.sersic_index = af.GaussianPrior(mean=4.0, sigma=0.5)\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__ \n",
        "\n",
        "We create the Analysis as per using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = ag.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "Below we use `PySwarmsGlobal` to fit the model, using the model where the particles start as described above. \n",
        "See the PySwarms docs for a description of what the input parameters below do and what the `Global` search technique is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.PySwarmsGlobal(\n",
        "    path_prefix=path.join(\"imaging\", \"searches\"),\n",
        "    name=\"PySwarmsGlobal\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_particles=30,\n",
        "    iters=300,\n",
        "    cognitive=0.5,\n",
        "    social=0.3,\n",
        "    inertia=0.9,\n",
        "    ftol=-np.inf,\n",
        "    iterations_per_update=1000,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "We can use an `MLEPlotter` to create a corner plot, which shows the probability density function (PDF) of every\n",
        "parameter in 1D and 2D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.MLEPlotter(samples=result.samples)\n",
        "plotter.cost_history()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can also use a `PySwarmsLocal` to fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.PySwarmsLocal(\n",
        "    path_prefix=path.join(\"imaging\", \"searches\"),\n",
        "    name=\"PySwarmsLocal\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_particles=30,\n",
        "    iters=300,\n",
        "    cognitive=0.5,\n",
        "    social=0.3,\n",
        "    inertia=0.9,\n",
        "    ftol=-np.inf,\n",
        "    iterations_per_update=1000,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "plotter = aplt.MLEPlotter(samples=result.samples)\n",
        "plotter.cost_history()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}