{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: Pixelization__\n",
        "\n",
        "This script provides a step-by-step guide of the **PyAutoGalaxy** `log_likelihood_function` which is used to fit\n",
        "`Imaging` data with a pixelization (specifically a `RectangularMagnification` mesh and `Constant` regularization scheme`).\n",
        "\n",
        "This example combines does not include a light profile or linear light profiles, which can be combined with a\n",
        "pixelization to fit an image. The inclusion of these components is described in the notebook\n",
        "`log_likelihood_function/imaging/pixelization/with_light_profile.ipynb`.\n",
        "\n",
        "This script has the following aims:\n",
        "\n",
        " - To provide a resource that authors can include in papers using **PyAutoGalaxy**, so that readers can understand the\n",
        " likelihood function (including references to the previous literature from which it is defined) without having to\n",
        " write large quantities of text and equations.\n",
        "\n",
        " - To make inversions in **PyAutoGalaxy** less of a \"black-box\" to users.\n",
        "\n",
        "Accompanying this script is the `contributor_guide.py` which provides URL's to every part of the source-code that\n",
        "is illustrated in this guide. This gives contributors a sequential run through of what source-code functions, modules and\n",
        "packages are called when the likelihood is evaluated.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "The likelihood function of a pixelization builds on that used for standard parametric light profiles and\n",
        "linear light profiles, therefore you must read the following notebooks before this script:\n",
        "\n",
        "- `light_profile/likelihood_function.ipynb`.\n",
        "- `linear_light_profile/likelihood_function.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `pixelization/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "Over sampling evaluates a light profile using multiple samples of its intensity per image-pixel.\n",
        "\n",
        "For simplicity, in previous likelihood function examples we disabled over sampling by setting `sub_size=1`. \n",
        "\n",
        "a full description of over sampling and how to use it is given in `autogalaxy_workspace/*/guides/over_sampling.py`.\n",
        "\n",
        "Over sampling is used for the same purpose in a pixelization, whereby it uses multiple samples of a pixel to\n",
        "perform the reconstruction via the pixelization. It uses an independent over sampling factor to the light profile\n",
        "over sampling factor, called `over_sample_size_pixelization`.\n",
        "\n",
        "For simplicity, we disable over sampling in this guide by setting `over_sample_size_pixelization=1`. \n",
        "\n",
        "The notebook `log_likelihood_function/imaging/pixelization/with_over_sampling.ipynb` describes how the likelihood\n",
        "function of a pixelization changes when over sampling is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_dataset = masked_dataset.apply_over_sampling(\n",
        "    over_sample_size_lp=1, over_sample_size_pixelization=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masked Image Grid__\n",
        "\n",
        "To perform galaxy calculations we define a 2D image-plane grid of (y,x) coordinates.\n",
        "\n",
        "For light profiles these are given by `masked_dataset.lp`, which is a uniform grid of (y,x) Cartesian coordinates\n",
        "which have had the 3.0\" circular mask applied.\n",
        "\n",
        "A pixelization uses a separate grid of (y,x) coordinates, called `masked_dataset.grids.pixelization`, which is\n",
        "identical to the light profile grid but may of had a different over-sampling scale applied (but in this example\n",
        "does not).\n",
        "\n",
        "Each (y,x) coordinate coordinates to the centre of each image-pixel in the dataset, meaning that when this grid is\n",
        "used to construct a pixelization there is a straight forward mapping between the image data and pixelization pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=masked_dataset.grids.pixelization)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy__\n",
        "\n",
        "We combine the pixelization into a single `Galaxy` object.\n",
        "\n",
        "The galaxy includes the rectangular mesh and constant regularization scheme, which will ultimately be used\n",
        "to reconstruct its star forming clumps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.RectangularMagnification(shape=(30, 30)),\n",
        "    regularization=ag.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = ag.Galaxy(redshift=0.5, pixelization=pixelization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Rectangular Mesh__\n",
        "\n",
        "The pixelization is used to create the rectangular mesh which is used to reconstruct the galaxy.\n",
        "\n",
        "The function below does this by overlaying the rectangular mesh over the masked image grid, such that the edges of\n",
        "the rectangular mesh touch the ask grid's edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_rectangular = ag.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=masked_dataset.grids.pixelization\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rectangular mesh will now be referred to interchangeably as the `source-plane`, to represent that it is a \n",
        "pixelization which will reconstruct a source of light,\n",
        "\n",
        "Plotting the rectangular mesh shows that the source-plane has been discretized into a grid of rectangular pixels.\n",
        "\n",
        "(To plot the rectangular mesh, we have to convert it to a `Mapper` object, which is described in the next likelihood \n",
        "step).\n",
        "\n",
        "Below, we plot the rectangular mesh without the image-grid pixels (for clarity) and with them as black dots in order\n",
        "to show how each set of image-pixels fall within a rectangular pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = ag.MapperGrids(\n",
        "    mask=mask,\n",
        "    source_plane_data_grid=masked_dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = ag.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)\n",
        "\n",
        "visuals = aplt.Visuals2D(\n",
        "    grid=mapper_grids.source_plane_data_grid,\n",
        ")\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, visuals_2d=visuals)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image-Source Mapping__\n",
        "\n",
        "We now combine grids computed above to create a `Mapper`, which describes how every masked image grid pixel maps to\n",
        "every rectangular pixelization pixel. \n",
        "\n",
        "There are two steps in this calculation, which we show individually below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = ag.MapperGrids(\n",
        "    mask=mask,\n",
        "    source_plane_data_grid=masked_dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = ag.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Mapper` contains:\n",
        "\n",
        " 1) `source_plane_data_grid`: the grid of masked (y,x) image-pixel coordinate centres (`masked_dataset.grids.pixelization`).\n",
        " 2) `source_plane_mesh_grid`: The rectangular mesh of (y,x) pixelization pixel coordinates (`grid_rectangular`).\n",
        "\n",
        "We have therefore discretized the source-plane into a rectangular mesh, and can pair every image-pixel coordinate\n",
        "with the corresponding rectangular pixel it lands in.\n",
        "\n",
        "This pairing is contained in the ndarray `pix_indexes_for_sub_slim_index` which maps every image-pixel index to \n",
        "every pixelization pixel index.\n",
        "\n",
        "In the API, the `pix_indexes` refers to the pixelization pixel indexes (e.g. rectangular pixel 0, 1, 2 etc.) \n",
        "and `sub_slim_index`  refers to the index of an image pixel (e.g. image-pixel 0, 1, 2 etc.). \n",
        "\n",
        "For example, printing the first ten entries of `pix_indexes_for_sub_slim_index` shows the first ten rectanfgular \n",
        "pixelization pixel indexes these image sub-pixels map too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pix_indexes_for_sub_slim_index = mapper.pix_indexes_for_sub_slim_index\n",
        "\n",
        "print(pix_indexes_for_sub_slim_index[0:9])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This array can be used to visualize how an input list of image-pixel indexes map to the rectangular pixelization.\n",
        "\n",
        "It also shows that image-pixel indexing begins from the top-left and goes rightwards and downwards, accounting for \n",
        "all image-pixels which are not masked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(indexes=[list(range(2050, 2090))])\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=masked_dataset.data, interpolate_to_uniform=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reverse mappings of pixelization pixels to image-pixels can also be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pix_indexes = [[200]]\n",
        "\n",
        "indexes = mapper.slim_indexes_for_pix_indexes(pix_indexes=pix_indexes)\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=indexes)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=masked_dataset.data, interpolate_to_uniform=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `mapping_matrix` represents the image-pixel to source-pixel mappings above in a 2D matrix. \n",
        "\n",
        "It has dimensions `(total_image_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "(A number of inputs are not used for the `RectangularMagnification` mesh and are expanded upon in the `with_interpolation.ipynb`\n",
        "log likelihood guide notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = ag.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows of all image-pixelization pixel mappings.\n",
        "\n",
        "No row of pixels has more than one non-zero entry. It is not possible for two image pixels to map to the same \n",
        "pixelization pixel (meaning that there are no correlated pixels in the mapping matrix)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each column of the `mapping_matrix` can therefore be used to show all image-pixels it maps too. \n",
        "\n",
        "For example, above, we plotted all image-pixels of pixelization pixel 200 (as well as 202 and 204). We can extract all\n",
        "image-pixel indexes of pixelization pixels 200 using the `mapping_matrix` and use them to plot the image of this\n",
        "pixelization pixel (which corresponds to only values of zeros or ones)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indexes_pix_200 = np.nonzero(mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_pix_200[0])\n",
        "\n",
        "array_2d = ag.Array2D(values=mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Blurred Mapping Matrix ($f$)__\n",
        "\n",
        "Each pixelization pixel can therefore be thought of as an image (where all entries of this image are zeros and ones). \n",
        "\n",
        "To incorporate the imaging data's PSF, we simply blur each one of these pixelization pixel images with the imaging \n",
        "data's Point Spread Function (PSF) via 2D convolution.\n",
        "\n",
        "This operation does not change the dimensions of the mapping matrix, meaning the `blurred_mapping_matrix` also has\n",
        "dimensions `(total_image_pixels, total_rectangular_pixels)`. It turns the values of zeros and ones into \n",
        "non-integer values which have been blurred by the PSF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "blurred_mapping_matrix = masked_dataset.psf.convolved_mapping_matrix_from(\n",
        "    mapping_matrix=mapping_matrix\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `blurred_mapping_matrix` shows all image-source pixel mappings including PSF blurring.\n",
        "\n",
        "Note how, unlike for the `mapping_matrix`, every row of image-pixels now has multiple non-zero entries. It is now \n",
        "possible for two image pixels to map to the same source pixel, because they become correlated by PSF convolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    blurred_mapping_matrix,\n",
        "    aspect=(blurred_mapping_matrix.shape[1] / blurred_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each column of the `blurred_mapping_matrix` shows all image-pixels it maps to after PSF blurring. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indexes_pix_200 = np.nonzero(blurred_mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_pix_200[0])\n",
        "\n",
        "array_2d = ag.Array2D(values=blurred_mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Warren & Dye 2003 (https://arxiv.org/abs/astro-ph/0302587) the `blurred_mapping_matrix` is denoted $f_{ij}$\n",
        "where $i$ maps over all $I$ source pixels and $j$ maps over all $J$ image pixels. \n",
        "\n",
        "For example: \n",
        "\n",
        " - $f_{0, 2} = 0.3$ indicates that image-pixel $2$ maps to pixelization pixel $0$ with a weight of $0.3$ after PSF convolution.\n",
        " - $f_{4, 8} = 0$ indicates that image-pixel $8$ does not map to pixelization pixel $4$, even after PSF convolution.\n",
        "\n",
        "The indexing of the `mapping_matrix` is reversed compared to the notation of WD03 (e.g. image pixels\n",
        "are the first entry of `mapping_matrix` whereas for $f$ they are the second index)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Mapping between image pixel 0 and rectangular pixel 2 = {mapping_matrix[0, 2]}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Vector (D)__\n",
        "\n",
        "To solve for the rectangular pixel fluxes we now pose the problem as a linear inversion.\n",
        "\n",
        "This requires us to convert the `blurred_mapping_matrix` and our `data` and `noise map` into matrices of certain dimensions. \n",
        "\n",
        "The `data_vector`, $D$, is the first matrix and it has dimensions `(total_rectangular_pixels,)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) and N15 (https://arxiv.org/abs/1412.7436) the data vector \n",
        "is give by: \n",
        "\n",
        " $\\vec{D}_{i} = \\sum_{\\rm  j=1}^{J}f_{ij}(d_{j})/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "Where:\n",
        "\n",
        " - $d_{\\rm j}$ are the image-pixel data flux values.\n",
        " - $\\sigma{\\rm _j}^2$ are the statistical uncertainties of each image-pixel value.\n",
        "\n",
        "$i$ maps over all $I$ source pixels and $j$ maps over all $J$ image pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = ag.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(masked_dataset.data),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$D$ describes which deconvolved rectangular pixels trace to which image-plane pixels. This ensures the \n",
        "reconstruction fully accounts for the PSF when fitting the data.\n",
        "\n",
        "We can plot $D$ as a column vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dimensions of $D$ are the number of source pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Data Vector:\")\n",
        "print(data_vector)\n",
        "print(data_vector.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix (F)__\n",
        "\n",
        "The `curvature_matrix` $F$ is the second matrix and it has \n",
        "dimensions `(total_rectangular_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "In WD03 / N15 (https://arxiv.org/abs/astro-ph/0302587) the curvature matrix is a 2D matrix given by:\n",
        "\n",
        " ${F}_{ik} = \\sum_{\\rm  j=1}^{J}f_{ij}f_{kj}/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "NOTE: this notation implicitly assumes a summation over $K$, where $k$ runs over all pixelization pixel indexes $K$.\n",
        "\n",
        "Note how summation over $J$ runs over $f$ twice, such that every entry of $F$ is the sum of the multiplication\n",
        "between all values in every two columns of $f$.\n",
        "\n",
        "For example, $F_{0,1}$ is the sum of every blurred image pixels values in $f$ of source pixel 0 multiplied by\n",
        "every blurred image pixel value of source pixel 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_matrix = ag.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For $F_{ik}$ to be non-zero, this requires that the images of rectangular pixels $i$ and $k$ share at least one\n",
        "image-pixel, which we saw above is only possible due to PSF blurring.\n",
        "\n",
        "For example, we can see a non-zero entry for $F_{100,101}$ and plotting their images\n",
        "show overlap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_pixel_0 = 0\n",
        "source_pixel_1 = 1\n",
        "\n",
        "print(curvature_matrix[source_pixel_0, source_pixel_1])\n",
        "\n",
        "array_2d = ag.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_0], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "array_2d = ag.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_1], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following chi-squared is minimized when we perform the inversion and reconstruct the galaxy:\n",
        "\n",
        "$\\chi^2 = \\sum_{\\rm  j=1}^{J} \\bigg[ \\frac{(\\sum_{\\rm  i=1}^{I} s_{i} f_{ij}) - d_{j}}{\\sigma_{j}} \\bigg]$\n",
        "\n",
        "Where $s$ is the reconstructed pixel fluxes in all $I$ rectangular pixels.\n",
        "\n",
        "The solution for $s$ is therefore given by (equation 5 WD03):\n",
        "\n",
        " $s = F^{-1} D$\n",
        "\n",
        "We can compute this using NumPy linear algebra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Because we are no using regularizartion (see below) it is common for the curvature matrix to be singular and lead\n",
        "# to a LinAlgException. The loop below mitigates this -- you can ignore it as it is not important for understanding\n",
        "# the PyAutoGalaxy likelihood function.\n",
        "\n",
        "for i in range(curvature_matrix.shape[0]):\n",
        "    curvature_matrix[i, i] += 1e-8\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot this reconstruction -- it looks like a mess.\n",
        "\n",
        "The pixelization pixels have noisy and unsmooth values, and it is hard to make out if a galaxy is even being \n",
        "reconstructed. \n",
        "\n",
        "In fact, the linear inversion is (over-)fitting noise in the image data, meaning this system of equations is \n",
        "ill-posed. We need to apply some form of smoothing on the reconstruction to avoid over fitting noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization Matrix (H)__\n",
        "\n",
        "Regularization adds a linear regularization term $G_{\\rm L}$ to the $\\chi^2$ we solve for giving us a new merit \n",
        "function $G$ (equation 11 WD03):\n",
        "\n",
        " $G = \\chi^2 + \\lambda \\, G_{\\rm L}$\n",
        "\n",
        "where $\\lambda$ is the `regularization_coefficient` which describes the magnitude of smoothness that is applied. A \n",
        "higher $\\lambda$ will regularize the source more, leading to a smoother galaxy reconstruction.\n",
        "\n",
        "Different forms for $G_{\\rm L}$ can be defined which regularize the reconstruction in different ways. The \n",
        "`Constant` regularization scheme used in this example applies gradient regularization (equation 14 WD03):\n",
        "\n",
        " $G_{\\rm L} = \\sum_{\\rm  i}^{I} \\sum_{\\rm  n=1}^{N}  [s_{i} - s_{i, v}]$\n",
        "\n",
        "This regularization scheme is easier to express in words -- the summation goes to each rectangular pixelization pixel,\n",
        "determines all rectangular pixels with which it shares a direct vertex (e.g. its neighbors) and penalizes solutions \n",
        "where the difference in reconstructed flux of these two neighboring pixels is large.\n",
        "\n",
        "The summation does this for all rectangular pixels, thus it favours solutions where neighboring rectangular \n",
        "pixels reconstruct similar values to one another (e.g. it favours a smooth galaxy reconstruction).\n",
        "\n",
        "We now define the `regularization matrix`, $H$, which allows us to include this smoothing when we solve for $s$. $H$\n",
        "has dimensions `(total_rectangular_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "This relates to $G_{\\rm L}$ as (equation 13 WD03):\n",
        "\n",
        " $H_{ik} = \\frac{1}{2} \\frac{\\partial G_{\\rm L}}{\\partial s_{i} \\partial s_{k}}$\n",
        "\n",
        "$H$ has the `regularization_coefficient` $\\lambda$ folded into it such $\\lambda$'s control on the degree of smoothing\n",
        "is accounted for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_matrix = ag.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the regularization matrix and note that:\n",
        "\n",
        " - non-zero entries indicate that two rectangular pixelization pixels are neighbors and therefore are regularized \n",
        " with one another.\n",
        "\n",
        " - Zeros indicate the two rectangular pixels do not neighbor one another.\n",
        "\n",
        "The majority of entries are zero, because the majority of rectangular pixels are not neighbors with one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(regularization_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__F + Lamdba H__\n",
        "\n",
        "$H$ enters the linear algebra system we solve for as follows (WD03 equation (12)):\n",
        "\n",
        " $s = [F + H]^{-1} D$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Reconstruction (s)__\n",
        "\n",
        "We can now solve the linear system above using NumPy linear algebra. \n",
        "\n",
        "Note that the for loop used above to prevent a LinAlgException is no longer required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting this galaxy reconstruction we can see that regularization has lead us to reconstruct a smoother galaxy,\n",
        "which actually looks like the star forming clumps in the galaxy imaging data! \n",
        "\n",
        "This also implies we are not over-fitting the noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image Reconstruction__\n",
        "\n",
        "Using the reconstructed pixel fluxes we can map the reconstruction back to the image plane (via \n",
        "the `blurred mapping_matrix`) and produce a reconstruction of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapped_reconstructed_image_2d = (\n",
        "    ag.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = ag.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "We now quantify the goodness-of-fit of our pixelization galaxy reconstruction. \n",
        "\n",
        "We compute the `log_likelihood` of the fit, which is the value returned by the `log_likelihood_function`.\n",
        "\n",
        "The likelihood function for galaxy modeling consists of five terms:\n",
        "\n",
        " $-2 \\mathrm{ln} \\, \\epsilon = \\chi^2 + s^{T} H s + \\mathrm{ln} \\, \\left[ \\mathrm{det} (F + H) \\right] - { \\mathrm{ln}} \\, \\left[ \\mathrm{det} (H) \\right] + \\sum_{\\rm  j=1}^{J} { \\mathrm{ln}} \\left [2 \\pi (\\sigma_j)^2 \\right]  \\, .$\n",
        "\n",
        "This expression was first derived by Suyu 2006 (https://arxiv.org/abs/astro-ph/0601493) and is given by equation (19).\n",
        "It was derived into **PyAutoGalaxy** notation in Dye 2008 (https://arxiv.org/abs/0804.4002) equation (5).\n",
        "\n",
        "We now explain what each of these terms mean.\n",
        "\n",
        "__Chi Squared__\n",
        "\n",
        "The first term is a $\\chi^2$ statistic, which is defined above in our merit function as and is computed as follows:\n",
        "\n",
        " - `model_data` = `mapped_reconstructed_image_2d`\n",
        " - `residual_map` = (`data` - `model_data`)\n",
        " - `normalized_residual_map` = (`data` - `model_data`) / `noise_map`\n",
        " - `chi_squared_map` = (`normalized_residuals`) ** 2.0 = ((`data` - `model_data`)**2.0)/(`variances`)\n",
        " - `chi_squared` = sum(`chi_squared_map`)\n",
        "\n",
        "The chi-squared therefore quantifies if our fit to the data is accurate or not. \n",
        "\n",
        "High values of chi-squared indicate that there are many image pixels our model did not produce a good fit to the image \n",
        "for, corresponding to a fit with a lower likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `chi_squared_map` indicates which regions of the image we did and did not fit accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chi_squared_map = ag.Array2D(values=chi_squared_map, mask=mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=chi_squared_map)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization Term__\n",
        "\n",
        "The second term, $s^{T} H s$, corresponds to the $\\lambda $G_{\\rm L}$ regularization term we added to our merit \n",
        "function above.\n",
        "\n",
        "This is the term which sums up the difference in flux of all reconstructed rectangular pixels, and reduces the \n",
        "likelihood of solutions where there are large differences in flux (e.g. the galaxy is less smooth and more likely to be \n",
        "overfitting noise).\n",
        "\n",
        "We compute it below via matrix multiplication, noting that the `regularization_coefficient`, $\\lambda$, is built into \n",
        "the `regularization_matrix` already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "print(regularization_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Complexity Terms__\n",
        "\n",
        "Up to this point, it is unclear why we chose a value of `regularization_coefficient=1.0`. \n",
        "\n",
        "We cannot rely on the `chi_squared` and `regularization_term` above to optimally choose its value, because increasing \n",
        "the `regularization_coefficient` smooths the solution more and therefore:\n",
        "\n",
        " - Decreases `chi_squared` by fitting the data worse, producing a lower `log_likelihood`.\n",
        "\n",
        " - Increases the `regularization_term` by penalizing the differences between source pixel fluxes more, again reducing\n",
        " the inferred `log_likelihood`.\n",
        "\n",
        "If we set the regularization coefficient based purely on these two terms, we would set a value of 0.0 and be back where\n",
        "we started over-fitting noise!\n",
        "\n",
        "The terms $\\left[ \\mathrm{det} (F + H) \\right]$ and $ - { \\mathrm{ln}} \\, \\left[ \\mathrm{det} (H) \\right]$ address \n",
        "this problem. \n",
        "\n",
        "They quantify how complex the reconstruction is, and penalize solutions where *it is more complex*. Reducing \n",
        "the `regularization_coefficient` makes the galaxy reconstruction more complex (because a galaxy that is \n",
        "smoothed less uses more flexibility to fit the data better).\n",
        "\n",
        "These two terms therefore counteract the `chi_squared` and `regularization_term`, so as to attribute a higher\n",
        "`log_likelihood` to solutions which fit the data with a more smoothed and less complex source (e.g. one with a higher \n",
        "`regularization_coefficient`).\n",
        "\n",
        "In **HowToGalaxy** -> `chapter 4` -> `tutorial_4_bayesian_regularization` we expand on this further and give a more\n",
        "detailed description of how these different terms impact the `log_likelihood_function`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "print(log_curvature_reg_matrix_term)\n",
        "print(log_regularization_matrix_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Normalization Term__\n",
        "\n",
        "Our likelihood function assumes the imaging data consists of independent Gaussian noise in every image pixel.\n",
        "\n",
        "The final term ins the likelihood function is therefore a `noise_normalization` term, which consists of the sum\n",
        "of the log of every noise-map value squared. \n",
        "\n",
        "Given the `noise_map` is fixed, this term does not change during the galaxy modeling process and has no impact on the \n",
        "model we infer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_normalization = float(np.sum(np.log(2 * np.pi * masked_dataset.noise_map**2.0)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Calculate The Log Likelihood__\n",
        "\n",
        "We can now, finally, compute the `log_likelihood` of the galaxy model, by combining the five terms computed above using\n",
        "the likelihood function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation is what is performed in the `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies = ag.Galaxies(galaxies=[galaxy])\n",
        "\n",
        "fit = ag.FitImaging(\n",
        "    dataset=masked_dataset,\n",
        "    galaxies=galaxies,\n",
        "    settings_inversion=ag.SettingsInversion(\n",
        "        use_w_tilde=False, use_border_relocator=True\n",
        "    ),\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Modeling__\n",
        "\n",
        "To fit a galaxy model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `nautilus` (https://github.com/joshspeagle/nautilus)\n",
        "but **PyAutoGalaxy** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the pixelization likelihood function.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in this package. In brief, these describe:\n",
        "\n",
        " - **Over Sampling**: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " paired fractionally with each rectangular pixel.\n",
        "\n",
        " - **Source-plane Interpolation**: Using bilinear interpolation on the rectangular pixelization to pair each \n",
        " image (sub-)pixel to multiple rectangular pixels with interpolation weights.\n",
        "\n",
        " - **Luminosity Weighted Regularization**: Using an adaptive regularization coefficient which adapts the level of \n",
        " regularization applied to the galaxy based on its luminosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# %%\n",
        "'''\n",
        "__Log Likelihood Function: Pixelization With Light Profile__\n",
        "\n",
        "This script describes how a pixelization, with light profiles or linear light profiles included, changes the likelihood\n",
        "calculation of a pixelization.\n",
        "\n",
        "It directly follows on from the `pixelization/log_likelihood_function.py` notebook and you should read through that\n",
        "script before reading this script.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "You must read through the following likelihood functions first:\n",
        "\n",
        " - `pixelization/log_likelihood_function.py` the likelihood function for a pixelization.\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `pixelization/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "masked_dataset = masked_dataset.apply_over_sampling(\n",
        "    over_sample_size_lp=1, over_sample_size_pixelization=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__With Standard Light Profiles__\n",
        "\n",
        "Combining standard light profiles with a pixelization is simple, and basically changes the pixelization likelihood\n",
        "function as follows:\n",
        "\n",
        "1) The image of the light profiles are computed, summed and convolved with the PSF using the standard methods.\n",
        "\n",
        "2) This image is subtracted from the observed image to create a light subtracted image, which is the image that\n",
        "   enters the pixelization linear inversion calculation.\n",
        "\n",
        "3) The light profile images are addded back on to the pixelization's reconstructed image to create the model image\n",
        "   that is compared to the observed image.\n",
        "\n",
        "The code below repeats the `pixelization/log_likelihood_function.py` example, but with the addition of the light \n",
        "profiles.\n",
        "\n",
        "Text is only included for steps which differ from the example in `pixelization/log_likelihood_function.py`.\n",
        "\n",
        "__Galaxy__\n",
        "\n",
        "The light profiles are created and combined with the `Pixelization` to create a `Galaxy` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = ag.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=ag.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    intensity=0.2,\n",
        "    effective_radius=0.8,\n",
        "    sersic_index=4.0,\n",
        ")\n",
        "\n",
        "disk = ag.lp.Exponential(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=ag.convert.ell_comps_from(axis_ratio=0.7, angle=30.0),\n",
        "    intensity=0.1,\n",
        "    effective_radius=1.6,\n",
        ")\n",
        "\n",
        "pixelization = ag.Pixelization(\n",
        "    mesh=ag.mesh.RectangularMagnification(shape=(30, 30)),\n",
        "    regularization=ag.reg.Constant(coefficient=1.0),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Light Subtracted Image__\n",
        "\n",
        "The image of the light profiles is computed, convolved with the PSF and subtracted from the observed image\n",
        "to create the light subtracted image which will be input to the pixelization linear inversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy = ag.Galaxy(redshift=0.5, bulge=bulge, disk=disk, pixelization=pixelization)\n",
        "\n",
        "image = galaxy.image_2d_from(grid=masked_dataset.grid)\n",
        "blurring_image_2d = galaxy.image_2d_from(grid=masked_dataset.grids.blurring)\n",
        "\n",
        "convolved_image_2d = masked_dataset.psf.convolved_image_from(\n",
        "    image=image, blurring_image=blurring_image_2d\n",
        ")\n",
        "\n",
        "light_subtracted_image_2d = masked_dataset.data - convolved_image_2d\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=light_subtracted_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "Steps creating the `mapping_matrix` and blurred_mapping_matrix` are identical to the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_rectangular = ag.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=masked_dataset.grids.pixelization\n",
        ")\n",
        "\n",
        "mapper_grids = ag.MapperGrids(\n",
        "    mask=mask,\n",
        "    source_plane_data_grid=masked_dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = ag.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapping_matrix = ag.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=mapper.pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")\n",
        "\n",
        "blurred_mapping_matrix = masked_dataset.psf.convolved_mapping_matrix_from(\n",
        "    mapping_matrix=mapping_matrix\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Vector (D)__\n",
        "\n",
        "The step which creates the `data_vector` is updated, as it now receives the light subtracted image as input.\n",
        "\n",
        "The `data_vector`, $D$, is now defined algebraically as \n",
        "\n",
        " $\\vec{D}_{i} = \\sum_{\\rm  j=1}^{J}f_{ij}(d_{j} - b_{j})/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "Where:\n",
        "\n",
        " - $d_{\\rm j}$ are again the image-pixel data flux values and $\\sigma{\\rm _j}^2$ are the statistical uncertainties of each image-pixel value.\n",
        " - $b_{\\rm j}$ is a new quantity, they are the brightness values of the bulge and disk light model (therefore $d_{\\rm  j} - b_{\\rm j}$ is \n",
        " the bulge and disk light subtracted image).\n",
        "\n",
        "$i$ maps over all $I$ source pixels and $j$ maps over all $J$ image pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = ag.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(light_subtracted_image_2d),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Alegbra__\n",
        "\n",
        "Steps creating the `curvature_matrix` and other quantities are identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_matrix = ag.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "regularization_matrix = ag.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)\n",
        "\n",
        "mapped_reconstructed_image_2d = (\n",
        "    ag.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = ag.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Image__\n",
        "\n",
        "Whereas previously the model image was only the reconstructed image, it now includes the light profile image.\n",
        "\n",
        "The following chi-squared is therefore now minimized when we perform the inversion and reconstruct the galaxy:\n",
        "\n",
        "$\\chi^2 = \\sum_{\\rm  j=1}^{J} \\bigg[ \\frac{(\\sum_{\\rm  i=1}^{I} s_{i} f_{ij}) + b_{j} - d_{j}}{\\sigma_{j}} \\bigg]$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "model_image = convolved_image_2d + mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "The overall likelihood function is the same as before, except the model image now includes the light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = convolved_image_2d + mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__With Linear Light Profiles__\n",
        "\n",
        "Code examples of how linear light profiles are combined with a pixelization are not provided in this script, as they\n",
        "are not yet written.\n",
        "\n",
        "Conceptually, the main difference between linear light profiles and standard light profiles is that the linear light\n",
        "profiles enter the linear algebra calculations and are solved for simultaneously with the pixelization. A summary of\n",
        "how this changes the calculation is provided below:\n",
        "\n",
        "- The data fitted is now the original data and does not have the light profiles subtracted from it, as the linear\n",
        "  algebra calculation now solves for the light profiles simultaneously with the pixelization.\n",
        "\n",
        "- The `mapping_matrix`, which for a pixelization has shape `(total_image_pixels, total_pixelization_pixels)`, has \n",
        "  rows added to it for every linear light profile, meaning its \n",
        "  shape is `(total_image_pixels, total_pixelization_pixels + total_linear_light_profiles)`.\n",
        "\n",
        "- Each light profile column of this `mapping_matrix` is the image of each linear light profile, meaning that their\n",
        " `intensity` values are solved for simultaneously with the pixelization's `flux` values.\n",
        "\n",
        "- The use of the positive only solver for the reconstruction is more important, because linear light profiles and\n",
        "  pixelizations can trade-off negative values between one another and produce unphysical solutions.\n",
        "\n",
        "Other than the above change, the calculation is performed in an identical manner to the pixelization example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}