{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Features: Pixelization Modeling\n",
        "===============================\n",
        "\n",
        "A pixelization reconstructs a galaxy\u2019s light using a pixel grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a galaxy model which uses a pixelization to reconstruct the galaxy\u2019s light.\n",
        "\n",
        "A rectangular mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "and provide computationally fast and accurate solutions.\n",
        "\n",
        "For simplicity, the galaxy is modeled using only a pixelized light component. Including additional parametric\n",
        "light components is straightforward and can be done within the same framework.\n",
        "\n",
        "You may wish to first read the `pixelization/fit.py` example, which demonstrates how a pixelized galaxy reconstruction\n",
        "is applied to a single dataset.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__Run Time Overview__\n",
        "\n",
        "Pixelized galaxy reconstructions are computed using either GPU acceleration via JAX or CPU acceleration via `numba`.\n",
        "\n",
        "The faster option depends on two crucial factors:\n",
        "\n",
        "#### **1. GPU VRAM Limitations**\n",
        "JAX only provides significant acceleration on GPUs with **large VRAM (\u226516 GB)**.\n",
        "To avoid excessive VRAM usage, examples often restrict pixelization meshes (e.g. 20 \u00d7 20).\n",
        "On consumer GPUs with limited memory, **JAX may be slower than CPU execution**.\n",
        "\n",
        "#### **2. Sparse Matrix Performance**\n",
        "\n",
        "Pixelized inversions require operations on **very large, highly sparse matrices**.\n",
        "\n",
        "- JAX currently lacks sparse-matrix support and must compute using **dense matrices**, which scale poorly.\n",
        "- PyAutoGalaxy\u2019s CPU implementation (via `numba`) fully exploits sparsity, providing large speed gains\n",
        "  at **high image resolution** (e.g. `pixel_scales <= 0.03`).\n",
        "\n",
        "As a result, CPU execution can outperform JAX even on powerful GPUs for high-resolution datasets.\n",
        "\n",
        "The example `pixelization/cpu_fast_modeling` shows how to set up a pixelization to use efficient CPU calculations\n",
        "via the library `numba`.\n",
        "\n",
        "__Rule of Thumb__\n",
        "\n",
        "For **low-resolution imaging** (for example, datasets with `pixel_scales > 0.05`), modeling is generally faster using\n",
        "**JAX with a GPU**, because the computations involve fewer sparse operations and do not require large amounts of VRAM.\n",
        "\n",
        "For **high-resolution imaging** (for example, `pixel_scales <= 0.03`), modeling can be faster using a **CPU with numba**\n",
        "and multiple cores. At high resolution, the linear algebra is dominated by sparse matrix operations, and the CPU\n",
        "implementation exploits sparsity more effectively, especially on systems with many CPU cores (e.g. HPC clusters).\n",
        "\n",
        "**Recommendation:** The best choice depends on your hardware and dataset. If your data has resolution of 0.1\" per pixel\n",
        "(e.g. Euclid imaging) or lower, JAX will often be the most efficient. For higher resolution imaging (e.g. HST, JWST),\n",
        "it is worth benchmarking both approaches (GPU+JAX vs CPU+numba) to determine which performs fastest for your case.\n",
        "\n",
        "__Contents__\n",
        "\n",
        "**Advantages & Disadvantages:** Benefits and drawbacks of using a pixelization to model galaxy light.\n",
        "**Positive Only Solver:** How a positive solution to the reconstructed pixel fluxes is ensured.\n",
        "**Dataset & Mask:** Standard setup of the imaging dataset that is fitted.\n",
        "**Pixelization:** How to create a pixelization, including a description of its inputs.\n",
        "**Model:** Composing a model using a pixelization and how it changes the number of free parameters.\n",
        "**Search & Analysis:** Standard setup of non-linear search and analysis.\n",
        "**Run Time:** Profiling of pixelization run times and discussion of how they compare to analytic light profiles.\n",
        "**Model-Fit:** Performs the model fit using the standard API.\n",
        "**Result:** Pixelization results and visualization.\n",
        "**Including Smooth Components:** How to combine a pixelization with parametric light profiles to model both smooth and complex galaxy structures.\n",
        "**Chaining:** How the advanced modeling feature, non-linear search chaining, can significantly improve lens modeling with pixelizaitons.\n",
        "**Result (Advanced):** API for various pixelization outputs (magnifications, mappings) which requires some polishing.\n",
        "**Simulate (Advanced):** Simulating a strong lens dataset with the inferred pixelized source.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many galaxies exhibit complex, asymmetric, and irregular morphologies. Such structures cannot be well approximated by\n",
        "analytic light profiles such as a S\u00e9rsic profile, or even combinations of multiple S\u00e9rsic components. Pixelizations are\n",
        "therefore required to accurately reconstruct this irregular galaxy light.\n",
        "\n",
        "Even alternative basis-function approaches, such as shapelets or multi-Gaussian expansions, struggle to accurately\n",
        "reconstruct galaxies with highly complex morphologies or multiple distinct components.\n",
        "\n",
        "Pixelized galaxy models are therefore essential when the goal is to recover detailed structure in galaxy light\n",
        "distributions beyond what is possible with parametric profiles.\n",
        "\n",
        "Finally, many science applications aim to study galaxy morphology itself in detail, particularly for faint or\n",
        "low-surface-brightness features. Pixelizations reconstruct the intrinsic galaxy light distribution, enabling these\n",
        "studies.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelized galaxy reconstructions are computationally more expensive than analytic light-profile models. For\n",
        "high-resolution imaging data (e.g. Hubble Space Telescope observations), fits using pixelizations can require\n",
        "significantly longer run times.\n",
        "\n",
        "Modeling galaxy light with pixelizations is also conceptually more complex, with additional failure modes compared to\n",
        "parametric models, such as overfitting noise or producing overly complex reconstructions if regularization is not\n",
        "chosen carefully.\n",
        "\n",
        "As a result, learning to successfully fit galaxy models with pixelizations typically requires more time and\n",
        "experience than the simpler modeling approaches introduced elsewhere in the workspace.\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "Many codes which use linear algebra rely on solvers that allow both positive and negative values of the solution\n",
        "(e.g. `np.linalg.solve`), because they are computationally fast.\n",
        "\n",
        "This is problematic, as it allows negative surface-brightness values to represent a galaxy\u2019s light, which is clearly\n",
        "unphysical. For a pixelization, this often produces negative pixels that over-fit the data, leading to unphysical\n",
        "solutions.\n",
        "\n",
        "All pixelized galaxy reconstructions therefore use a positive-only solver, meaning that every pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the reconstruction is physical and prevents unphysical\n",
        "negative solutions.\n",
        "\n",
        "Enforcing this efficiently requires non-trivial linear algebra, so a bespoke fast non-negative solver was developed;\n",
        "many methods in the literature omit this and therefore allow unphysical solutions that can degrade galaxy modeling\n",
        "results.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a galaxy with a model where:\n",
        "\n",
        " - The galaxy\u2019s surface brightness is reconstructed using a pixelization.\n",
        " - A `RectangularAdaptDensity` mesh and `Constant` regularization scheme are used.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "\n",
        "Load and plot the strong lens dataset `simple__sersic` via .fits files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__sersic\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "A pixelization uses a separate grid for light evaluation, with its own over sampling scheme, which below we set to a \n",
        "uniform grid of values of 4. \n",
        "\n",
        "Note that the over sampling is input into the `over_sample_size_pixelization` because we are using a `Pixelization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "over_sample_size = ag.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[8, 4, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_pixelization=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "In JAX, calculations must use static shaped arrays with known and fixed indexes. For certain calculations in the\n",
        "pixelization, this information has to be passed in before the pixelization is performed. Below, we do this for 3\n",
        "inputs:\n",
        "\n",
        "- `total_linear_light_profiles`: The number of linear light profiles in the model. This is 0 because we are not\n",
        "  fitting any linear light profiles to the data, primarily because the lens light is omitted.\n",
        "\n",
        "- `total_mapper_pixels`: The number of source pixels in the rectangular pixelization mesh. This is required to set up \n",
        "  the arrays that perform the linear algebra of the pixelization.\n",
        "\n",
        "- `source_pixel_zeroed_indices`: The indices of source pixels on its edge, which when the source is reconstructed \n",
        "  are forced to values of zero, a technique tests have shown are required to give accruate lens models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = ag.Preloads(\n",
        "    mapper_indices=ag.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=ag.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example we fit a model where:\n",
        "\n",
        " - The galaxy's light uses a 20 x 20 `RectangularAdaptDensity` mesh [0 parameters]. \n",
        " \n",
        " - This pixelization is regularized using a `GaussianKernel` scheme which smooths every source [2 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=2. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (3 parameters) than \n",
        "fitting this complex galaxy using parametric light profiles would (20+ parameters). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = af.Model(\n",
        "    ag.Pixelization,\n",
        "    mesh=ag.mesh.RectangularAdaptDensity(shape=mesh_shape),\n",
        "    regularization=ag.reg.GaussianKernel,\n",
        ")\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using a non-linear search. In this example, we use the nested sampling algorithm \n",
        "Nautilus (https://nautilus.readthedocs.io/en/latest/).\n",
        "\n",
        "A full description of the settings below is given in the beginner modeling scripts, if anything is unclear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"imaging\") / \"features\",\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    n_batch=20,  # GPU lens model fits are batched and run simultaneously, see VRAM section below.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = ag.AnalysisImaging(dataset=dataset, preloads=preloads, use_jax=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__VRAM__\n",
        "\n",
        "The `modeling` example explains how VRAM is used during GPU-based fitting and how to print the estimated VRAM \n",
        "required by a model.\n",
        "\n",
        "pixelizations use a lot more VRAM than light profile-only models, with the amount required depending on the size of\n",
        "dataset and the number of source pixels in the pixelization's mesh. For 400 source pixels, around 0.05 GB per batched\n",
        "likelihood of VRAM is used. \n",
        "\n",
        "This is why the `batch_size` above is 20, lower than other examples, because reducing the batch size ensures a more \n",
        "modest amount of VRAM is used. If you have a GPU with more VRAM, increasing the batch size will lead to faster run times.\n",
        "\n",
        "Given VRAM use is an important consideration, we print out the estimated VRAM required for this \n",
        "model-fit and advise you do this for your own pixelization model-fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis.print_vram_use(model=model, batch_size=search.batch_size)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of a pixelization are fast provided that the GPU VRAM exceeds the amount of memory required to perform\n",
        "a likelihood evaluation.\n",
        "\n",
        "Assuming the use of a 20 x 20 mesh grid above means this is the case, the run times of this model-fit on a GPU\n",
        "should take under 10 minutes. If VRAM is exceeded, the run time will be significantly longer (3+ hours). CPU run\n",
        "times are also of order hours, but can be sped up using the `numba` library (see the `pixelization/cpu` example).\n",
        "\n",
        "The run times of pixelizations slow down as the data becomes higher resolution. In this example, data with a pixel\n",
        "scale of 0.1\" gives of order 10 minute run times (when VRAM is under control), for a pixel scale of 0.05\" this\n",
        "becomes around 30 minutes, and an hour for 0.03\".\n",
        "\n",
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, galaxy images and posteriors inferred via Nautilus.\n",
        "\n",
        "The galaxy bulge and disk appear similar to those in the data, confirming that the `intensity` values inferred by\n",
        "the inversion process are accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "galaxies_plotter = aplt.GalaxiesPlotter(\n",
        "    galaxies=result.max_log_likelihood_galaxies, grid=result.grids.lp\n",
        ")\n",
        "galaxies_plotter.subplot()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_cornerpy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Including Smooth Components__\n",
        "\n",
        "By combining a pixelization with parametric light profiles, we can model galaxies whose light consists of both smooth\n",
        "and complex, irregular components. For example, we can quantify the light in bulge and disk components while\n",
        "simultaneously reconstructing irregular features such as spiral arms or star-forming clumps using a pixelization.\n",
        "This allows a physically meaningful decomposition of a galaxy into its main structural components and a robust\n",
        "measurement of their properties.\n",
        "\n",
        "Combining a pixelization with parametric light profiles is straightforward: we simply add light profiles to the\n",
        "galaxy model alongside the pixelization using the standard modeling API. Below, we use linear light profiles to\n",
        "maximize computational efficiency, although non-linear light profiles can also be used.\n",
        "\n",
        "For brevity, we do not perform the model fit here. The code below demonstrates how to construct such a model, which\n",
        "can then be fitted using the same search and analysis objects introduced above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = af.Model(\n",
        "    ag.Pixelization,\n",
        "    bulge=ag.lp_linear.Sersic,\n",
        "    disk=ag.lp_linear.Exponential,\n",
        "    mesh=ag.mesh.RectangularAdaptDensity(shape=mesh_shape),\n",
        "    regularization=ag.reg.GaussianKernel,\n",
        ")\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask Extra Galaxies__\n",
        "\n",
        "There may be extra galaxies nearby the main galaxy, whose emission blends with it.\n",
        "\n",
        "If their emission is significant, and close enough to the galaxy, we may simply remove the emission from the data\n",
        "to ensure it does not impact the model-fit. A standard masking approach would be to remove the image pixels containing\n",
        "the emission of these galaxies altogether. This is analogous to what the circular masks used throughout the examples\n",
        "does.\n",
        "\n",
        "For fits using a pixelization, masking regions of the image in a way that removes their image pixels entirely from\n",
        "the fit. This can produce discontinuities in the pixelixation used to reconstruct the source and produce unexpected\n",
        "systematics and unsatisfactory results. In this case, applying the mask in a way where the image pixels are not\n",
        "removed from the fit, but their data and noise-map values are scaled such that they contribute negligibly to the fit,\n",
        "is a better approach.\n",
        "\n",
        "We illustrate the API for doing this below, using the `extra_galaxies` dataset which has extra galaxies whose emission\n",
        "needs to be removed via scaling in this way. We apply the scaling and show the subplot imaging where the extra\n",
        "galaxies mask has scaled the data values to zeros, increasing the noise-map values to large values and in turn made\n",
        "the signal to noise of its pixels effectively zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"extra_galaxies\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_extra_galaxies = ag.Mask2D.from_fits(\n",
        "    file_path=Path(dataset_path, \"mask_extra_galaxies.fits\"),\n",
        "    pixel_scales=0.1,\n",
        "    invert=True,  # Note that we invert the mask here as `True` means a pixel is scaled.\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_noise_scaling(mask=mask_extra_galaxies)\n",
        "\n",
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=0.1, centre=(0.0, 0.0), radius=6.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do not explictly fit this data, for the sake of brevity, however if your data has these nearby galaxies you should\n",
        "apply the mask as above before fitting the data.\n",
        "\n",
        "__Result Use__\n",
        "\n",
        "There are many things you can do with the result of a pixelixaiton, including analysing the galaxy reconstruction.\n",
        "\n",
        "These are documented in the `fit.py` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "Pixelizations are the most complex but also the most powerful way to model a galaxy\u2019s light.\n",
        "\n",
        "Whether you need to use them depends on the science you are doing. If you are only interested in measuring simple\n",
        "global quantities (for example, total flux, size, or axis ratio), analytic light profiles such as a S\u00e9rsic, MGE, or\n",
        "shapelets are often sufficient. For low-resolution data, pixelizations are also unnecessary, as the complex\n",
        "structure of the galaxy is not resolved.\n",
        "\n",
        "However, modeling galaxies with complex, irregular, or highly structured light distributions requires this level of\n",
        "flexibility. Furthermore, if you are interested in studying the detailed morphology of a galaxy itself, there is no\n",
        "better approach than using a pixelization.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Modeling with a pixelization can be made more efficient, robust, and automated using the non-linear chaining feature\n",
        "to compose a pipeline that begins by fitting a simpler model using parametric light profiles.\n",
        "\n",
        "More information on chaining is provided in the\n",
        "`autogalaxy_workspace/notebooks/guides/modeling/chaining` folder and in chapter 3 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__HowToGalaxy__\n",
        "\n",
        "A full description of how pixelizations work\u2014which relies heavily on linear algebra, Bayesian statistics, and\n",
        "2D geometry\u2014is provided in chapter 4 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More diagnostic quantities for reconstructed galaxy light.\n",
        "- Gradient calculations of the reconstructed light distribution.\n",
        "- Quantifying spatial variations in galaxy structure across the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}