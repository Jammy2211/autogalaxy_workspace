{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Light Inversion\n",
        "=========================\n",
        "\n",
        "This script fits an `Imaging` dataset of a galaxy with a model where:\n",
        "\n",
        " - The galaxy's light is modeled using an `Inversion` with a rectangular pixelization and constant regularization\n",
        " scheme.\n",
        "\n",
        "An `Inversion` reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "this reconstruction to be smooth. Due to the simplicity of this example the inversion effectively just find a model\n",
        "galaxy image that is denoised and deconvolved.\n",
        "\n",
        "More complicated and useful inversion fits are given elsewhere in the workspace (e.g. the `chaining` package), where\n",
        "they are combined with light profiles to fit irregular galaxies in a efficient way.\n",
        "\n",
        "Inversions are covered in detail in chapter 4 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in generag.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autogalaxy as ag\n",
        "import autogalaxy.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the galaxy dataset `complex` via .fits files, where:\n",
        " \n",
        "  -The galaxy's bulge is an `Sersic`.\n",
        " - The galaxy's disk is an `Exponential`.\n",
        " - The galaxy's has four star forming clumps which are `Sersic` profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__sersic\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = ag.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ag.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "Apply adaptive over sampling to ensure the calculation is accurate, you can read up on over-sampling in more detail via \n",
        "the `autogalaxy_workspace/*/guides/over_sampling.ipynb` notebook.\n",
        "\n",
        "Note that the over sampling is input into the `over_sample_size_pixelization` because we are using a `Pixelization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "over_sample_size = ag.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[8, 4, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_pixelization=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "In JAX, calculations must use static shaped arrays with known and fixed indexes. For certain calculations in the\n",
        "pixelization, this information has to be passed in before the pixelization is performed. Below, we do this for 3\n",
        "inputs:\n",
        "\n",
        "- `total_linear_light_profiles`: The number of linear light profiles in the model. This is 0 because we are not\n",
        "  fitting any linear light profiles to the data, primarily because the lens light is omitted.\n",
        "\n",
        "- `total_mapper_pixels`: The number of source pixels in the rectangular pixelization mesh. This is required to set up \n",
        "  the arrays that perform the linear algebra of the pixelization.\n",
        "\n",
        "- `source_pixel_zeroed_indices`: The indices of source pixels on its edge, which when the source is reconstructed \n",
        "  are forced to values of zero, a technique tests have shown are required to give accruate lens models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = ag.Preloads(\n",
        "    mapper_indices=ag.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=ag.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example we fit a model where:\n",
        "\n",
        " - The galaxy's light uses a 20 x 20 `RectangularMagnification` mesh [0 parameters]. \n",
        " \n",
        " - This pixelization is regularized using a `Constant` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=3. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (3 parameters) than \n",
        "fitting this complex galaxy using parametric light profiles would (20+ parameters). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = af.Model(\n",
        "    ag.Pixelization,\n",
        "    mesh=ag.mesh.RectangularMagnification(shape=mesh_shape),\n",
        "    regularization=ag.reg.GaussianKernel,\n",
        ")\n",
        "\n",
        "galaxy = af.Model(ag.Galaxy, redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using a non-linear search. In this example, we use the nested sampling algorithm \n",
        "Nautilus (https://nautilus.readthedocs.io/en/latest/).\n",
        "\n",
        "A full description of the settings below is given in the beginner modeling scripts, if anything is unclear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"imaging\") / \"features\",\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    n_like_max=200,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the model is fitted to the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = ag.AnalysisImaging(dataset=dataset, preloads=preloads, use_jax=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, galaxy images and posteriors inferred via Nautilus.\n",
        "\n",
        "The galaxy bulge and disk appear similar to those in the data, confirming that the `intensity` values inferred by\n",
        "the inversion process are accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "galaxies_plotter = aplt.GalaxiesPlotter(\n",
        "    galaxies=result.max_log_likelihood_galaxies, grid=result.grids.lp\n",
        ")\n",
        "galaxies_plotter.subplot()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_cornerpy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result (Advanced)__\n",
        "\n",
        "The code belows shows all additional results that can be computed from a `Result` object following a fit with a\n",
        "pixelization.\n",
        "\n",
        "__Max Likelihood Inversion__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit`, which contains the\n",
        "`Inversion` object we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This `Inversion` can be used to plot the reconstructed image of specifically all linear light profiles and the\n",
        "reconstruction of the `Pixelization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion_plotter = aplt.InversionPlotter(inversion=inversion)\n",
        "inversion_plotter.figures_2d(reconstructed_image=True)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction CSV__\n",
        "\n",
        "In the results `image` folder there is a .csv file called `source_plane_reconstruction_0.csv` which contains the\n",
        "y and x coordinates of the pixelization mesh, the reconstruct values and the noise map of these values.\n",
        "\n",
        "This file is provides all information on the source reconstruciton in a format that does not depend autolens\n",
        "and therefore be easily loaded to create images of the source or shared collaobrations who do not have PyAutoLens\n",
        "installed.\n",
        "\n",
        "First, lets load `source_plane_reconstruction_0.csv` as a dictionary, using basic `csv` functionality in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import csv\n",
        "\n",
        "    with open(\n",
        "        search.paths.image_path / \"source_plane_reconstruction_0.csv\", mode=\"r\"\n",
        "    ) as file:\n",
        "        reader = csv.reader(file)\n",
        "        header_list = next(reader)  # ['y', 'x', 'reconstruction', 'noise_map']\n",
        "\n",
        "        reconstruction_dict = {header: [] for header in header_list}\n",
        "\n",
        "        for row in reader:\n",
        "            for key, value in zip(header_list, row):\n",
        "                reconstruction_dict[key].append(float(value))\n",
        "\n",
        "        # Convert lists to NumPy arrays\n",
        "        for key in reconstruction_dict:\n",
        "            reconstruction_dict[key] = np.array(reconstruction_dict[key])\n",
        "\n",
        "    print(reconstruction_dict[\"y\"])\n",
        "    print(reconstruction_dict[\"x\"])\n",
        "    print(reconstruction_dict[\"reconstruction\"])\n",
        "    print(reconstruction_dict[\"noise_map\"])\n",
        "except FileNotFoundError:\n",
        "    print(\n",
        "        \"CSV file not found. Please ensure the model-fit has been run and the file exists.\"\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More \n",
        "- Source gradient calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}